{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loisll/MMAI984/blob/main/lois_trainmodel_Team_Project_VQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STEP 1: Import Libraries"
      ],
      "metadata": {
        "id": "6tFQaOxS6kEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: Import libraries\n",
        "!pip install torch torchvision transformers\n",
        "!pip install tqdm\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "\n"
      ],
      "metadata": {
        "id": "2jO3Rar8UkF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b95ca2-8189-47b7-d639-963207c7d377"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "0aSiwO_X7Gdl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y91qSbw0mgDO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STEP 2: LOAD TRAIN DATA"
      ],
      "metadata": {
        "id": "MrIfrgQt6qCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for loading questions and annotations\n",
        "\n",
        "def load_data(data_file, feature):\n",
        "\n",
        "  # Check if the file exists\n",
        "  if os.path.exists(data_file):\n",
        "    print(\"File found:\", data_file)\n",
        "\n",
        "    # Load the JSON file using the json module\n",
        "    with open(data_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Convert the JSON data to a DataFrame\n",
        "    # questions = pd.DataFrame(data)\n",
        "\n",
        "    # Flatten the JSON structure\n",
        "    data = pd.json_normalize(data[feature])\n",
        "\n",
        "    # Question preprocessing\n",
        "\n",
        "    print(\"Data loaded successfully\")\n",
        "  else:\n",
        "    print(\"File not found:\", data_file)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "9u2juAo2b-h9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training questions\n",
        "\n",
        "# Define the questions file\n",
        "train_questions_file = os.path.join(data_path, 'train2015/MultipleChoice_abstract_v002_train2015_questions.json')\n",
        "#train_questions_file = os.path.join(data_path)\n",
        "train_questions_feature = 'questions'\n",
        "train_questions = load_data(train_questions_file, train_questions_feature )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the annotations file\n",
        "train_annotations_file = os.path.join(data_path, 'train2015/abstract_v002_train2015_annotations.json')\n",
        "train_annotations_feature = 'annotations'\n",
        "train_annotations = load_data(train_annotations_file, train_annotations_feature)\n",
        "\n",
        "\n",
        "\n",
        "# Define the annotations file\n",
        "train_captions_file = os.path.join(data_path, 'train2015/captions_abstract_v002_train2015.json')\n",
        "train_captions_feature = 'images'\n",
        "train_captions = load_data(train_captions_file, train_captions_feature)\n",
        "\n",
        "\n",
        "\n",
        "# Define the annotations file\n",
        "train_OpenEnded_file = os.path.join(data_path, 'train2015/OpenEnded_abstract_v002_train2015_questions.json')\n",
        "train_OpenEnded_feature = 'questions'\n",
        "train_OpenEnded = load_data(train_OpenEnded_file, train_OpenEnded_feature)"
      ],
      "metadata": {
        "id": "tS6fZlUDdtlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64453fc9-e1fa-4eda-c57d-1b999e7df1d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found: /content/drive/My Drive/Colab Notebooks/train2015/MultipleChoice_abstract_v002_train2015_questions.json\n",
            "Data loaded successfully\n",
            "File found: /content/drive/My Drive/Colab Notebooks/train2015/abstract_v002_train2015_annotations.json\n",
            "Data loaded successfully\n",
            "File found: /content/drive/My Drive/Colab Notebooks/train2015/captions_abstract_v002_train2015.json\n",
            "Data loaded successfully\n",
            "File found: /content/drive/My Drive/Colab Notebooks/train2015/OpenEnded_abstract_v002_train2015_questions.json\n",
            "Data loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 MERGE TRAIN DATA"
      ],
      "metadata": {
        "id": "MCHBaOrZ63z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge questions and answers\n",
        "\n",
        "#train_data = pd.merge(train_questions, train_annotations, on='question_id')\n",
        "train_data = pd.merge(train_questions, train_annotations, on=[\"image_id\", \"question_id\"])\n",
        "\n",
        "df_train = train_data.merge(train_captions, on='image_id')\n",
        "df_train.head(5)"
      ],
      "metadata": {
        "id": "qo1I9qDYS_eh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "dbb0dfe2-c2ef-433d-c900-3146b10843dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id                     question  \\\n",
              "0     11779           Who looks happier?   \n",
              "1     11779  Where is the woman sitting?   \n",
              "2     11779    Where is the man sitting?   \n",
              "3      5536          Is this man hungry?   \n",
              "4      5536  What kind of drink is that?   \n",
              "\n",
              "                                    multiple_choices  question_id  \\\n",
              "0  [alive, 1, woman, purple, 2, yes, white, boy, ...       117792   \n",
              "1  [3, no, blue, red, 1, slide, monkey bars, jump...       117790   \n",
              "2  [away, yes, blue, 1, 2, mouse, couch, no, yell...       117791   \n",
              "3  [water, yellow, 4, running, blue, pouring, out...        55360   \n",
              "4  [wine, girl would fall, soda, white, yes, coke...        55361   \n",
              "\n",
              "  question_type multiple_choice_answer  \\\n",
              "0           who                    man   \n",
              "1  where is the                blanket   \n",
              "2  where is the                  bench   \n",
              "3       is this                    yes   \n",
              "4  what kind of                   soda   \n",
              "\n",
              "                                             answers answer_type  \\\n",
              "0  [{'answer': 'old person', 'answer_confidence':...       other   \n",
              "1  [{'answer': 'on blanket', 'answer_confidence':...       other   \n",
              "2  [{'answer': 'on bench', 'answer_confidence': '...       other   \n",
              "3  [{'answer': 'yes', 'answer_confidence': 'yes',...      yes/no   \n",
              "4  [{'answer': 'water', 'answer_confidence': 'no'...       other   \n",
              "\n",
              "                                                 url  \\\n",
              "0  http://visualqa.org/data/abstract_v002/scene_i...   \n",
              "1  http://visualqa.org/data/abstract_v002/scene_i...   \n",
              "2  http://visualqa.org/data/abstract_v002/scene_i...   \n",
              "3  http://visualqa.org/data/abstract_v002/scene_i...   \n",
              "4  http://visualqa.org/data/abstract_v002/scene_i...   \n",
              "\n",
              "                                  file_name  width  height  \n",
              "0  abstract_v002_train2015_000000011779.png    700     400  \n",
              "1  abstract_v002_train2015_000000011779.png    700     400  \n",
              "2  abstract_v002_train2015_000000011779.png    700     400  \n",
              "3  abstract_v002_train2015_000000005536.png    700     400  \n",
              "4  abstract_v002_train2015_000000005536.png    700     400  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebbbbe16-b354-4953-801a-8b5198d28eca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>question</th>\n",
              "      <th>multiple_choices</th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_type</th>\n",
              "      <th>multiple_choice_answer</th>\n",
              "      <th>answers</th>\n",
              "      <th>answer_type</th>\n",
              "      <th>url</th>\n",
              "      <th>file_name</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11779</td>\n",
              "      <td>Who looks happier?</td>\n",
              "      <td>[alive, 1, woman, purple, 2, yes, white, boy, ...</td>\n",
              "      <td>117792</td>\n",
              "      <td>who</td>\n",
              "      <td>man</td>\n",
              "      <td>[{'answer': 'old person', 'answer_confidence':...</td>\n",
              "      <td>other</td>\n",
              "      <td>http://visualqa.org/data/abstract_v002/scene_i...</td>\n",
              "      <td>abstract_v002_train2015_000000011779.png</td>\n",
              "      <td>700</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11779</td>\n",
              "      <td>Where is the woman sitting?</td>\n",
              "      <td>[3, no, blue, red, 1, slide, monkey bars, jump...</td>\n",
              "      <td>117790</td>\n",
              "      <td>where is the</td>\n",
              "      <td>blanket</td>\n",
              "      <td>[{'answer': 'on blanket', 'answer_confidence':...</td>\n",
              "      <td>other</td>\n",
              "      <td>http://visualqa.org/data/abstract_v002/scene_i...</td>\n",
              "      <td>abstract_v002_train2015_000000011779.png</td>\n",
              "      <td>700</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11779</td>\n",
              "      <td>Where is the man sitting?</td>\n",
              "      <td>[away, yes, blue, 1, 2, mouse, couch, no, yell...</td>\n",
              "      <td>117791</td>\n",
              "      <td>where is the</td>\n",
              "      <td>bench</td>\n",
              "      <td>[{'answer': 'on bench', 'answer_confidence': '...</td>\n",
              "      <td>other</td>\n",
              "      <td>http://visualqa.org/data/abstract_v002/scene_i...</td>\n",
              "      <td>abstract_v002_train2015_000000011779.png</td>\n",
              "      <td>700</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5536</td>\n",
              "      <td>Is this man hungry?</td>\n",
              "      <td>[water, yellow, 4, running, blue, pouring, out...</td>\n",
              "      <td>55360</td>\n",
              "      <td>is this</td>\n",
              "      <td>yes</td>\n",
              "      <td>[{'answer': 'yes', 'answer_confidence': 'yes',...</td>\n",
              "      <td>yes/no</td>\n",
              "      <td>http://visualqa.org/data/abstract_v002/scene_i...</td>\n",
              "      <td>abstract_v002_train2015_000000005536.png</td>\n",
              "      <td>700</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5536</td>\n",
              "      <td>What kind of drink is that?</td>\n",
              "      <td>[wine, girl would fall, soda, white, yes, coke...</td>\n",
              "      <td>55361</td>\n",
              "      <td>what kind of</td>\n",
              "      <td>soda</td>\n",
              "      <td>[{'answer': 'water', 'answer_confidence': 'no'...</td>\n",
              "      <td>other</td>\n",
              "      <td>http://visualqa.org/data/abstract_v002/scene_i...</td>\n",
              "      <td>abstract_v002_train2015_000000005536.png</td>\n",
              "      <td>700</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebbbbe16-b354-4953-801a-8b5198d28eca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ebbbbe16-b354-4953-801a-8b5198d28eca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ebbbbe16-b354-4953-801a-8b5198d28eca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-554b1362-f100-4ee2-9ac2-2db0450bed51\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-554b1362-f100-4ee2-9ac2-2db0450bed51')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-554b1362-f100-4ee2-9ac2-2db0450bed51 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 60000,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5773,\n        \"min\": 0,\n        \"max\": 19999,\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          15209,\n          1943,\n          3582\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34841,\n        \"samples\": [\n          \"Is there a doll in the doll house?\",\n          \"Are the curtains exactly the same?\",\n          \"Does this scene take place in summer?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"multiple_choices\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57735,\n        \"min\": 0,\n        \"max\": 199992,\n        \"num_unique_values\": 60000,\n        \"samples\": [\n          168601,\n          5252,\n          116061\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 81,\n        \"samples\": [\n          \"is the old man\",\n          \"who\",\n          \"is there a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"multiple_choice_answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2521,\n        \"samples\": [\n          \"playing soccer\",\n          \"she fell\",\n          \"sitting on floor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answers\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"other\",\n          \"yes/no\",\n          \"number\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          \"http://visualqa.org/data/abstract_v002/scene_img/img/15209.png\",\n          \"http://visualqa.org/data/abstract_v002/scene_img/img/1943.png\",\n          \"http://visualqa.org/data/abstract_v002/scene_img/img/3582.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          \"abstract_v002_train2015_000000015209.png\",\n          \"abstract_v002_train2015_000000001943.png\",\n          \"abstract_v002_train2015_000000003582.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 700,\n        \"max\": 700,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          700\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 400,\n        \"max\": 400,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          400\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0du6UDY_S_Si"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWVOS4oXS-25"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3 : EDA"
      ],
      "metadata": {
        "id": "ye92cJlTbbJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above examples, we can see that most of the questions and answers are simple and clean text but some questions contain punctuation, common word contractions like what’s, it’s, they’re, etc, and noun contractions like guy’s, man’s, dog’s, etc., and some answers also contain punctuation. Hence, we need to perform the data cleaning operation on the question and answer dataset and expand contractions before performing EDA."
      ],
      "metadata": {
        "id": "VdirF7O_apPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"he\\'s\", \"he is\", phrase)\n",
        "    phrase = re.sub(r\"she\\'s\", \"she is\", phrase)\n",
        "    phrase = re.sub(r\"it\\'s\", \"it is\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"he\\’s\", \"he is\", phrase)\n",
        "    phrase = re.sub(r\"she\\’s\", \"she is\", phrase)\n",
        "    phrase = re.sub(r\"it\\’s\", \"it is\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "\n",
        "def text_preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = decontractions(text) # replace contractions into natural form\n",
        "    text = re.sub('[-,:]', ' ', text) # replace the character \"-\" \",\" with space\n",
        "    text = re.sub(\"(?!<=\\d)(\\.)(?!\\d)\", '', text) # remove the character \".\", except from floating numbers\n",
        "    text = re.sub('[^A-Za-z0-9. ]+', '', text) # remove all punctuation, except A-Za-z0-9\n",
        "    text = re.sub(' +', ' ', text) # remove extra space\n",
        "    return text\n",
        "\n",
        "# Question and Answer text preprocessing\n",
        "df_train[\"question_preprocessed\"] = df_train[\"question\"].map(lambda x: text_preprocess(x))\n",
        "df_train[\"answer_preprocessed\"] = df_train[\"multiple_choice_answer\"].map(lambda x: text_preprocess(x))"
      ],
      "metadata": {
        "id": "qhNOwuXM7qqa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "HJNyfyZ47qkw",
        "outputId": "1163fbd0-bbe1-4bce-d915-098bc9735ec5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id                     question  \\\n",
              "0     11779           Who looks happier?   \n",
              "1     11779  Where is the woman sitting?   \n",
              "2     11779    Where is the man sitting?   \n",
              "\n",
              "                                    multiple_choices  question_id  \\\n",
              "0  [alive, 1, woman, purple, 2, yes, white, boy, ...       117792   \n",
              "1  [3, no, blue, red, 1, slide, monkey bars, jump...       117790   \n",
              "2  [away, yes, blue, 1, 2, mouse, couch, no, yell...       117791   \n",
              "\n",
              "  question_type multiple_choice_answer  \\\n",
              "0           who                    man   \n",
              "1  where is the                blanket   \n",
              "2  where is the                  bench   \n",
              "\n",
              "                                             answers answer_type  \\\n",
              "0  [{'answer': 'old person', 'answer_confidence':...       other   \n",
              "1  [{'answer': 'on blanket', 'answer_confidence':...       other   \n",
              "2  [{'answer': 'on bench', 'answer_confidence': '...       other   \n",
              "\n",
              "                                                 url  \\\n",
              "0  http://visualqa.org/data/abstract_v002/scene_i...   \n",
              "1  http://visualqa.org/data/abstract_v002/scene_i...   \n",
              "2  http://visualqa.org/data/abstract_v002/scene_i...   \n",
              "\n",
              "                                  file_name  width  height  \\\n",
              "0  abstract_v002_train2015_000000011779.png    700     400   \n",
              "1  abstract_v002_train2015_000000011779.png    700     400   \n",
              "2  abstract_v002_train2015_000000011779.png    700     400   \n",
              "\n",
              "        question_preprocessed answer_preprocessed  \n",
              "0           who looks happier                 man  \n",
              "1  where is the woman sitting             blanket  \n",
              "2    where is the man sitting               bench  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4189751-8a1e-4415-a702-f649127b3ec1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>question</th>\n",
              "      <th>multiple_choices</th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_type</th>\n",
              "      <th>multiple_choice_answer</th>\n",
              "      <th>answers</th>\n",
              "      <th>answer_type</th>\n",
              "      <th>url</th>\n",
              "      <th>file_name</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>question_preprocessed</th>\n",
              "      <th>answer_preprocessed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11779</td>\n",
              "      <td>Who looks happier?</td>\n",
              "      <td>[alive, 1, woman, purple, 2, yes, white, boy, ...</td>\n",
              "      <td>117792</td>\n",
              "      <td>who</td>\n",
              "      <td>man</td>\n",
              "      <td>[{'answer': 'old person', 'answer_confidence':...</td>\n",
              "      <td>other</td>\n",
              "      <td>http://visualqa.org/data/abstract_v002/scene_i...</td>\n",
              "      <td>abstract_v002_train2015_000000011779.png</td>\n",
              "      <td>700</td>\n",
              "      <td>400</td>\n",
              "      <td>who looks happier</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11779</td>\n",
              "      <td>Where is the woman sitting?</td>\n",
              "      <td>[3, no, blue, red, 1, slide, monkey bars, jump...</td>\n",
              "      <td>117790</td>\n",
              "      <td>where is the</td>\n",
              "      <td>blanket</td>\n",
              "      <td>[{'answer': 'on blanket', 'answer_confidence':...</td>\n",
              "      <td>other</td>\n",
              "      <td>http://visualqa.org/data/abstract_v002/scene_i...</td>\n",
              "      <td>abstract_v002_train2015_000000011779.png</td>\n",
              "      <td>700</td>\n",
              "      <td>400</td>\n",
              "      <td>where is the woman sitting</td>\n",
              "      <td>blanket</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11779</td>\n",
              "      <td>Where is the man sitting?</td>\n",
              "      <td>[away, yes, blue, 1, 2, mouse, couch, no, yell...</td>\n",
              "      <td>117791</td>\n",
              "      <td>where is the</td>\n",
              "      <td>bench</td>\n",
              "      <td>[{'answer': 'on bench', 'answer_confidence': '...</td>\n",
              "      <td>other</td>\n",
              "      <td>http://visualqa.org/data/abstract_v002/scene_i...</td>\n",
              "      <td>abstract_v002_train2015_000000011779.png</td>\n",
              "      <td>700</td>\n",
              "      <td>400</td>\n",
              "      <td>where is the man sitting</td>\n",
              "      <td>bench</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4189751-8a1e-4415-a702-f649127b3ec1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4189751-8a1e-4415-a702-f649127b3ec1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4189751-8a1e-4415-a702-f649127b3ec1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fc0cd672-3811-40f5-a5e0-550aa5726af2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc0cd672-3811-40f5-a5e0-550aa5726af2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fc0cd672-3811-40f5-a5e0-550aa5726af2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 60000,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5773,\n        \"min\": 0,\n        \"max\": 19999,\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          15209,\n          1943,\n          3582\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34841,\n        \"samples\": [\n          \"Is there a doll in the doll house?\",\n          \"Are the curtains exactly the same?\",\n          \"Does this scene take place in summer?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"multiple_choices\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57735,\n        \"min\": 0,\n        \"max\": 199992,\n        \"num_unique_values\": 60000,\n        \"samples\": [\n          168601,\n          5252,\n          116061\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 81,\n        \"samples\": [\n          \"is the old man\",\n          \"who\",\n          \"is there a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"multiple_choice_answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2521,\n        \"samples\": [\n          \"playing soccer\",\n          \"she fell\",\n          \"sitting on floor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answers\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"other\",\n          \"yes/no\",\n          \"number\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          \"http://visualqa.org/data/abstract_v002/scene_img/img/15209.png\",\n          \"http://visualqa.org/data/abstract_v002/scene_img/img/1943.png\",\n          \"http://visualqa.org/data/abstract_v002/scene_img/img/3582.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          \"abstract_v002_train2015_000000015209.png\",\n          \"abstract_v002_train2015_000000001943.png\",\n          \"abstract_v002_train2015_000000003582.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 700,\n        \"max\": 700,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          700\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 400,\n        \"max\": 400,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          400\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_preprocessed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 34688,\n        \"samples\": [\n          \"how many rectangles do you count in the smaller picture on the wall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_preprocessed\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2508,\n        \"samples\": [\n          \"he is happy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4 : Preprocess the Image--CNN"
      ],
      "metadata": {
        "id": "D77SM2d91XNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1. Encoding image size (batch size, channel, height, weight)\n"
      ],
      "metadata": {
        "id": "_lHagUWBz33l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "# 2. 加载图像并进行预处理\n",
        "def load_images_from_folder(folder_path):\n",
        "    images = []\n",
        "    count_id = []\n",
        "    for filename in os.listdir(folder_path): #get image from googledrive\n",
        "     if filename in df_sample_5k[\"file_name\"].values:\n",
        "       #only choose 5k sample from googledrive that match selected dataframe\n",
        "        if filename.endswith('.png'):  # only load PNG image\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path).convert('RGB')  # open and convert to  RGB\n",
        "            image_tensor = preprocess(image)  # preprocssing as  Tensor\n",
        "            images.append(image_tensor)\n",
        "            count_id.append(filename.split('.')[0])\n",
        "    return  torch.stack(images)  # 将所有 Tensor 拼接成一个批处理 (batch) 的 Tensor\n"
      ],
      "metadata": {
        "id": "6947RFalGuGT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cYd14DVVOLN0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Create CNN model and output as fully connected Layer (batch size, channel* height * weight)"
      ],
      "metadata": {
        "id": "8X2tBJIyaCdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: CNN Model After Image Encoding\n",
        "class CNNAfterEncoding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNAfterEncoding, self).__init__()\n",
        "        # Encoder (ResNet50)\n",
        "         # First Conv Layer: 3 input channels (RGB), 16 output channels, 3x3 kernel size\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Second Conv Layer: 16 input channels, 32 output channels, 3x3 kernel size\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Max Pool Layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully Connected (hidden) layer: Flatten the input to fit the fully connected layer\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 128)  # 32 filters, 56x56 feature map size after pooling twice\n",
        "\n",
        "        # Output layer: 128 input features, 10 output classes (example for classification)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through first Conv layer followed by ReLU and Max Pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Output: (batch_size, 16, 112, 112)\n",
        "\n",
        "        # Pass through second Conv layer followed by ReLU and Max Pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Output: (batch_size, 32, 56, 56)\n",
        "\n",
        "        # Flatten the tensor for the fully connected layer\n",
        "        x = x.view(-1, 32 * 56 * 56)  # Flatten to shape (batch_size, 32 * 56 * 56)\n",
        "\n",
        "        # Pass through the fully connected hidden layer\n",
        "        x = F.relu(self.fc1(x))  # Output: (batch_size, 128)\n",
        "\n",
        "        # # Pass through the final output layer\n",
        "        # x = self.fc2(x)  # Output: (batch_size, 10) - logits for 10 classes ...we dont need output for CNN\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Cmc1x0grFJPb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5 : Preprocessing the Question --RNN"
      ],
      "metadata": {
        "id": "PvP5JYffLKvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 将问题文本转换为索引\n",
        "def text_to_indices(df):\n",
        "      all_questions = \" \".join(df).split()\n",
        "      unique_words = list(set(all_questions))\n",
        "      word_to_index = {word: index for index, word in enumerate(unique_words)}\n",
        "      vocab_size = len(word_to_index)  # 词汇表大小\n",
        "      return [word_to_index[word] for word in all_questions if word in word_to_index]\n",
        "\n",
        "\n",
        "\n",
        "max_length = 10# 填充索引以使其具有相同的长度（假设最大长度为10）\n",
        "\n",
        "# question encoder\n",
        "def question_encoder(text,max_length):\n",
        "  questions_indices = [text_to_indices(question) for question in text ]\n",
        "  questions_indices_padded = [q + [0] * (max_length - len(q)) if len(q) < max_length else q[:max_length] for q in questions_indices]\n",
        "  questions_tensor = torch.tensor(questions_indices_padded, dtype=torch.long)# 将问题索引转换为 Tensor\n",
        "  return questions_tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 定义 QuestionEncoder 类\n",
        "class QuestionEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(QuestionEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, question):\n",
        "        embedded = self.embedding(question)\n",
        "        _, (hidden, _) = self.lstm(embedded)\n",
        "        return hidden[-1]  # 返回最后一层的隐藏状态\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f_OzsJn1MiBu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "frU_fZgLhENg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6 : Answer Encoder\n"
      ],
      "metadata": {
        "id": "pN4LNX5lrjxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answers = df_sample_5k[\"answer_preprocessed\"]\n",
        "\n",
        "# # Step 2: Create a vocabulary of all unique words\n",
        "# vocab = {word: idx for idx, word in enumerate(set(answers))}\n",
        "# print(\"Vocabulary:\", vocab)\n",
        "\n",
        "# # Example Output: {'blue': 0, 'yes': 1, 'no': 2, 'maybe': 3, 'red': 4, 'definitely': 5, 'sometimes': 6, 'green': 7}\n",
        "\n",
        "# # Step 3: Convert each answer into its corresponding index\n",
        "# answer_indices = [torch.tensor([vocab[word]]) for word in answers]\n",
        "# print(\"Answer Indices (before batching):\", answer_indices)\n",
        "\n",
        "# # Example Output: [tensor([1]), tensor([2]), tensor([3]), tensor([5]), tensor([1]), tensor([2]), ...]\n",
        "\n",
        "# # Step 4: Pad the sequences to ensure they have the same length\n",
        "# # Since these are single words, padding is not needed. But if the answers are sequences of different lengths:\n",
        "# encoded_answers_tensor = torch.tensor(answer_indices)\n",
        "# print(f\"Encoded answers tensor: {encoded_answers_tensor.shape}\")\n",
        "\n",
        "\n",
        "def answer_encoder(answers):\n",
        "       vocab = {word: idx for idx, word in enumerate(set(answers))}\n",
        "       answer_indices = [torch.tensor([vocab[word]]) for word in answers]\n",
        "       encoded_answers_tensor = torch.tensor(answer_indices)\n",
        "       return encoded_answers_tensor\n",
        ""
      ],
      "metadata": {
        "id": "LuS7DCy0saJA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "el0EzVu3r4dg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 7 :  Build VQA model"
      ],
      "metadata": {
        "id": "UySZlPCSLW-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# VQA model: Combine image and question features and predict the answer\n",
        "class VQAModel(nn.Module):\n",
        "    def __init__(self, image_feat_size, question_feat_size, hidden_size, answer_vocab_size):\n",
        "        super(VQAModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(image_feat_size + question_feat_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, answer_vocab_size)\n",
        "\n",
        "    def forward(self, image_features, question_features):\n",
        "        combined_features = torch.cat((image_features, question_features), dim=1) # COMBINE image fully connected layer and RNN fully connected layer\n",
        "        x = torch.relu(self.fc1(combined_features))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5iYRsCmU2now"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. VQA model"
      ],
      "metadata": {
        "id": "uFGp2cooi_4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "def main():\n",
        "    # Hyperparameters\n",
        "    vocab_size = 1000  # Example vocab size (should be equal to the number of unique tokens in your question dataset)\n",
        "    embed_size = 300\n",
        "    hidden_size = 512\n",
        "    num_layers = 1\n",
        "    answer_vocab_size = 100  # Example number of possible answers\n",
        "\n",
        "\n",
        "    #question_encoder = QuestionEncoder(vocab_size, embed_size, hidden_size, num_layers)\n",
        "    vqa_model = VQAModel(image_feat_size=128, question_feat_size=64, hidden_size=512, answer_vocab_size=answer_vocab_size)\n",
        "\n",
        "    #flattened_image_features = image_batch.view(batch_size, -1)\n",
        "    # Predict the answer\n",
        "    result = vqa_model(output, question_features)\n",
        "    #print(\"Model output (answer logits):\", result.shape) #18,100\n",
        "\n",
        "    # You would typically apply a softmax here to get answer probabilities\n",
        "    predicted_answer = torch.argmax(result, dim=1)\n",
        "    #print(\"Predicted answer index:\", predicted_answer)\n",
        "\n",
        "\n",
        "\n",
        "    # Use CrossEntropyLoss to compare logits and ground truth answers\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss = criterion(result, encoded_answers_tensor)\n",
        "    print(f\"Loss: {loss.item()}\")\n",
        "    return loss.item()\n",
        "\n"
      ],
      "metadata": {
        "id": "m0ymCMplAsue"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data path\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/'\n",
        "# Define the path to your zip file and the extraction destination\n",
        "extract_dir = os.path.join(data_path, 'train2015/train2015_images/scene_img_abstract_v002_train2015 (1)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDoAS9_ocICn",
        "outputId": "1037ed61-d59c-428d-ecca-921ed7e7bf9a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 8 : loop 5 times\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "idctmX8fcJSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_iterations = 1000\n",
        "final_loss_result=[]\n",
        "for i in range(n_iterations):\n",
        "    print(f\"Running model iteration {i + 1}\")\n",
        "    # get random 50 data\n",
        "    batch_size=50\n",
        "    df_sample_5k = df_train.sample(n=batch_size, replace=True, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "    # 模型参数\n",
        "    embed_size = 128     # 嵌入维度\n",
        "    hidden_size = 64     # LSTM 隐藏层维度\n",
        "    num_layers = 2       # LSTM 层数\n",
        "    vocab_size = 100 #len(word_to_index)  # 词汇表大小\n",
        "   # question feature , image feature and answer encoder\n",
        "    image_batch = load_images_from_folder(extract_dir)\n",
        "    model = CNNAfterEncoding()\n",
        "    output = model(image_batch)#final fully connected layer output\n",
        "\n",
        "\n",
        "    questions_tensor=question_encoder(df_sample_5k[\"question_preprocessed\"],max_length = 10)\n",
        "    model = QuestionEncoder(vocab_size, embed_size, hidden_size, num_layers)\n",
        "    question_features = model(questions_tensor)# 前向传播，获取问题特征\n",
        "    print(question_features.shape)\n",
        "\n",
        "\n",
        "    encoded_answers_tensor=answer_encoder(df_sample_5k[\"answer_preprocessed\"])\n",
        "\n",
        "    main()\n",
        "    lossitem=main()\n",
        "    final_loss_result.append(lossitem)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7llrF2w820J",
        "outputId": "39a4c381-3034-46b2-eea3-3a33cff2858d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model iteration 1\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616653919219971\n",
            "Loss: 4.619462966918945\n",
            "Running model iteration 2\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625426769256592\n",
            "Loss: 4.591889381408691\n",
            "Running model iteration 3\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609805583953857\n",
            "Loss: 4.604868412017822\n",
            "Running model iteration 4\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.584681034088135\n",
            "Loss: 4.6131415367126465\n",
            "Running model iteration 5\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620275020599365\n",
            "Loss: 4.605038642883301\n",
            "Running model iteration 6\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60001277923584\n",
            "Loss: 4.593937873840332\n",
            "Running model iteration 7\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59846305847168\n",
            "Loss: 4.607509136199951\n",
            "Running model iteration 8\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618932723999023\n",
            "Loss: 4.587910175323486\n",
            "Running model iteration 9\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599003791809082\n",
            "Loss: 4.617092132568359\n",
            "Running model iteration 10\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620975017547607\n",
            "Loss: 4.598250389099121\n",
            "Running model iteration 11\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5742692947387695\n",
            "Loss: 4.612488746643066\n",
            "Running model iteration 12\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617391586303711\n",
            "Loss: 4.591699123382568\n",
            "Running model iteration 13\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600756645202637\n",
            "Loss: 4.605118274688721\n",
            "Running model iteration 14\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6166157722473145\n",
            "Loss: 4.612414360046387\n",
            "Running model iteration 15\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5961594581604\n",
            "Loss: 4.613598823547363\n",
            "Running model iteration 16\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603116989135742\n",
            "Loss: 4.625576019287109\n",
            "Running model iteration 17\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59288215637207\n",
            "Loss: 4.598842144012451\n",
            "Running model iteration 18\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.576216220855713\n",
            "Loss: 4.622968673706055\n",
            "Running model iteration 19\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617204666137695\n",
            "Loss: 4.594460487365723\n",
            "Running model iteration 20\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601107597351074\n",
            "Loss: 4.623432636260986\n",
            "Running model iteration 21\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604761123657227\n",
            "Loss: 4.594133377075195\n",
            "Running model iteration 22\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601497650146484\n",
            "Loss: 4.610380172729492\n",
            "Running model iteration 23\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59597635269165\n",
            "Loss: 4.601345062255859\n",
            "Running model iteration 24\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6311445236206055\n",
            "Loss: 4.642990589141846\n",
            "Running model iteration 25\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597006797790527\n",
            "Loss: 4.618730545043945\n",
            "Running model iteration 26\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586055755615234\n",
            "Loss: 4.593571186065674\n",
            "Running model iteration 27\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591729164123535\n",
            "Loss: 4.598883152008057\n",
            "Running model iteration 28\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619565963745117\n",
            "Loss: 4.598844528198242\n",
            "Running model iteration 29\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608829498291016\n",
            "Loss: 4.6026225090026855\n",
            "Running model iteration 30\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610898017883301\n",
            "Loss: 4.613013744354248\n",
            "Running model iteration 31\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601945877075195\n",
            "Loss: 4.613008499145508\n",
            "Running model iteration 32\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604633808135986\n",
            "Loss: 4.581762790679932\n",
            "Running model iteration 33\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6154866218566895\n",
            "Loss: 4.606528282165527\n",
            "Running model iteration 34\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602136135101318\n",
            "Loss: 4.603897571563721\n",
            "Running model iteration 35\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6311492919921875\n",
            "Loss: 4.610240936279297\n",
            "Running model iteration 36\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610080242156982\n",
            "Loss: 4.577145576477051\n",
            "Running model iteration 37\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613428115844727\n",
            "Loss: 4.613428115844727\n",
            "Running model iteration 38\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5912065505981445\n",
            "Loss: 4.601110458374023\n",
            "Running model iteration 39\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605837821960449\n",
            "Loss: 4.60399866104126\n",
            "Running model iteration 40\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607621669769287\n",
            "Loss: 4.60862922668457\n",
            "Running model iteration 41\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596423149108887\n",
            "Loss: 4.6109089851379395\n",
            "Running model iteration 42\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5997209548950195\n",
            "Loss: 4.589836120605469\n",
            "Running model iteration 43\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606618404388428\n",
            "Loss: 4.609988212585449\n",
            "Running model iteration 44\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6021013259887695\n",
            "Loss: 4.590949535369873\n",
            "Running model iteration 45\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6153364181518555\n",
            "Loss: 4.609400749206543\n",
            "Running model iteration 46\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611111640930176\n",
            "Loss: 4.627447128295898\n",
            "Running model iteration 47\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607276439666748\n",
            "Loss: 4.620423316955566\n",
            "Running model iteration 48\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596472263336182\n",
            "Loss: 4.597972393035889\n",
            "Running model iteration 49\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.584158420562744\n",
            "Loss: 4.597011089324951\n",
            "Running model iteration 50\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620366096496582\n",
            "Loss: 4.600931167602539\n",
            "Running model iteration 51\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616984844207764\n",
            "Loss: 4.599743843078613\n",
            "Running model iteration 52\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588813781738281\n",
            "Loss: 4.585277557373047\n",
            "Running model iteration 53\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60276460647583\n",
            "Loss: 4.630974292755127\n",
            "Running model iteration 54\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593526363372803\n",
            "Loss: 4.62388801574707\n",
            "Running model iteration 55\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622950553894043\n",
            "Loss: 4.605590343475342\n",
            "Running model iteration 56\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.641462326049805\n",
            "Loss: 4.601986885070801\n",
            "Running model iteration 57\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.582006931304932\n",
            "Loss: 4.576417446136475\n",
            "Running model iteration 58\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593217372894287\n",
            "Loss: 4.610666751861572\n",
            "Running model iteration 59\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617281913757324\n",
            "Loss: 4.611342430114746\n",
            "Running model iteration 60\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591064453125\n",
            "Loss: 4.5975775718688965\n",
            "Running model iteration 61\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622450351715088\n",
            "Loss: 4.598598480224609\n",
            "Running model iteration 62\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586022853851318\n",
            "Loss: 4.590638160705566\n",
            "Running model iteration 63\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59971809387207\n",
            "Loss: 4.623621463775635\n",
            "Running model iteration 64\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.62515115737915\n",
            "Loss: 4.6104326248168945\n",
            "Running model iteration 65\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605743408203125\n",
            "Loss: 4.623272895812988\n",
            "Running model iteration 66\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598438262939453\n",
            "Loss: 4.613796234130859\n",
            "Running model iteration 67\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59805154800415\n",
            "Loss: 4.595337390899658\n",
            "Running model iteration 68\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603363513946533\n",
            "Loss: 4.6076860427856445\n",
            "Running model iteration 69\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594964504241943\n",
            "Loss: 4.599515914916992\n",
            "Running model iteration 70\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608811378479004\n",
            "Loss: 4.594963550567627\n",
            "Running model iteration 71\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602485179901123\n",
            "Loss: 4.594257831573486\n",
            "Running model iteration 72\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.583506107330322\n",
            "Loss: 4.596604347229004\n",
            "Running model iteration 73\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617730617523193\n",
            "Loss: 4.596288681030273\n",
            "Running model iteration 74\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613625526428223\n",
            "Loss: 4.603168487548828\n",
            "Running model iteration 75\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605201244354248\n",
            "Loss: 4.597616672515869\n",
            "Running model iteration 76\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597200870513916\n",
            "Loss: 4.624333381652832\n",
            "Running model iteration 77\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600359916687012\n",
            "Loss: 4.618899345397949\n",
            "Running model iteration 78\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6151041984558105\n",
            "Loss: 4.608997344970703\n",
            "Running model iteration 79\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613579273223877\n",
            "Loss: 4.580655574798584\n",
            "Running model iteration 80\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605574131011963\n",
            "Loss: 4.6344990730285645\n",
            "Running model iteration 81\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.63179874420166\n",
            "Loss: 4.599571228027344\n",
            "Running model iteration 82\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621497631072998\n",
            "Loss: 4.598936557769775\n",
            "Running model iteration 83\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595815658569336\n",
            "Loss: 4.612244606018066\n",
            "Running model iteration 84\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599542140960693\n",
            "Loss: 4.642717361450195\n",
            "Running model iteration 85\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598024368286133\n",
            "Loss: 4.6011552810668945\n",
            "Running model iteration 86\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614243984222412\n",
            "Loss: 4.623126983642578\n",
            "Running model iteration 87\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614847183227539\n",
            "Loss: 4.589603424072266\n",
            "Running model iteration 88\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6227827072143555\n",
            "Loss: 4.6074910163879395\n",
            "Running model iteration 89\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610883712768555\n",
            "Loss: 4.6319260597229\n",
            "Running model iteration 90\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.631215572357178\n",
            "Loss: 4.597773551940918\n",
            "Running model iteration 91\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613580703735352\n",
            "Loss: 4.604864597320557\n",
            "Running model iteration 92\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601168632507324\n",
            "Loss: 4.601530075073242\n",
            "Running model iteration 93\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.590559482574463\n",
            "Loss: 4.6033477783203125\n",
            "Running model iteration 94\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618025302886963\n",
            "Loss: 4.611362934112549\n",
            "Running model iteration 95\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606174468994141\n",
            "Loss: 4.601800441741943\n",
            "Running model iteration 96\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59514045715332\n",
            "Loss: 4.5972137451171875\n",
            "Running model iteration 97\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606996059417725\n",
            "Loss: 4.606679916381836\n",
            "Running model iteration 98\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596667289733887\n",
            "Loss: 4.593047618865967\n",
            "Running model iteration 99\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605642318725586\n",
            "Loss: 4.6208696365356445\n",
            "Running model iteration 100\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598268032073975\n",
            "Loss: 4.604650020599365\n",
            "Running model iteration 101\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594825267791748\n",
            "Loss: 4.6191205978393555\n",
            "Running model iteration 102\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610638618469238\n",
            "Loss: 4.586582183837891\n",
            "Running model iteration 103\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61630392074585\n",
            "Loss: 4.625639915466309\n",
            "Running model iteration 104\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604205131530762\n",
            "Loss: 4.598016738891602\n",
            "Running model iteration 105\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613379001617432\n",
            "Loss: 4.580506324768066\n",
            "Running model iteration 106\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594180107116699\n",
            "Loss: 4.625970840454102\n",
            "Running model iteration 107\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.585187911987305\n",
            "Loss: 4.601294994354248\n",
            "Running model iteration 108\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617705345153809\n",
            "Loss: 4.605402946472168\n",
            "Running model iteration 109\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610412120819092\n",
            "Loss: 4.605330944061279\n",
            "Running model iteration 110\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593465328216553\n",
            "Loss: 4.608944416046143\n",
            "Running model iteration 111\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616184234619141\n",
            "Loss: 4.595396995544434\n",
            "Running model iteration 112\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603206634521484\n",
            "Loss: 4.585851192474365\n",
            "Running model iteration 113\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597348690032959\n",
            "Loss: 4.618326187133789\n",
            "Running model iteration 114\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5904436111450195\n",
            "Loss: 4.599592208862305\n",
            "Running model iteration 115\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597350597381592\n",
            "Loss: 4.632308483123779\n",
            "Running model iteration 116\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.584041118621826\n",
            "Loss: 4.603853225708008\n",
            "Running model iteration 117\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600481986999512\n",
            "Loss: 4.60087251663208\n",
            "Running model iteration 118\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6073760986328125\n",
            "Loss: 4.589315414428711\n",
            "Running model iteration 119\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.623410224914551\n",
            "Loss: 4.601333141326904\n",
            "Running model iteration 120\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.579517841339111\n",
            "Loss: 4.62321138381958\n",
            "Running model iteration 121\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.628347396850586\n",
            "Loss: 4.610227584838867\n",
            "Running model iteration 122\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604248046875\n",
            "Loss: 4.584028720855713\n",
            "Running model iteration 123\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605856418609619\n",
            "Loss: 4.611438751220703\n",
            "Running model iteration 124\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604736328125\n",
            "Loss: 4.595056533813477\n",
            "Running model iteration 125\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601019859313965\n",
            "Loss: 4.5851054191589355\n",
            "Running model iteration 126\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.575995445251465\n",
            "Loss: 4.619691371917725\n",
            "Running model iteration 127\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619258403778076\n",
            "Loss: 4.603189468383789\n",
            "Running model iteration 128\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605777263641357\n",
            "Loss: 4.615584850311279\n",
            "Running model iteration 129\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604506015777588\n",
            "Loss: 4.6105055809021\n",
            "Running model iteration 130\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602609157562256\n",
            "Loss: 4.609766006469727\n",
            "Running model iteration 131\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607969284057617\n",
            "Loss: 4.6057329177856445\n",
            "Running model iteration 132\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616695880889893\n",
            "Loss: 4.599471569061279\n",
            "Running model iteration 133\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620797634124756\n",
            "Loss: 4.576684951782227\n",
            "Running model iteration 134\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594446182250977\n",
            "Loss: 4.5957183837890625\n",
            "Running model iteration 135\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616975784301758\n",
            "Loss: 4.602170944213867\n",
            "Running model iteration 136\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611159801483154\n",
            "Loss: 4.606015205383301\n",
            "Running model iteration 137\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618708610534668\n",
            "Loss: 4.598620891571045\n",
            "Running model iteration 138\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591613292694092\n",
            "Loss: 4.617279052734375\n",
            "Running model iteration 139\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618037223815918\n",
            "Loss: 4.598130702972412\n",
            "Running model iteration 140\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596611499786377\n",
            "Loss: 4.5951104164123535\n",
            "Running model iteration 141\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593591213226318\n",
            "Loss: 4.646017074584961\n",
            "Running model iteration 142\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609397888183594\n",
            "Loss: 4.592656135559082\n",
            "Running model iteration 143\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.577449798583984\n",
            "Loss: 4.617918491363525\n",
            "Running model iteration 144\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604372024536133\n",
            "Loss: 4.6069488525390625\n",
            "Running model iteration 145\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607633113861084\n",
            "Loss: 4.606280326843262\n",
            "Running model iteration 146\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619370937347412\n",
            "Loss: 4.6190996170043945\n",
            "Running model iteration 147\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593411445617676\n",
            "Loss: 4.608397006988525\n",
            "Running model iteration 148\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592696666717529\n",
            "Loss: 4.590243339538574\n",
            "Running model iteration 149\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622035980224609\n",
            "Loss: 4.596958637237549\n",
            "Running model iteration 150\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.615367412567139\n",
            "Loss: 4.603968620300293\n",
            "Running model iteration 151\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588812828063965\n",
            "Loss: 4.620466232299805\n",
            "Running model iteration 152\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600074291229248\n",
            "Loss: 4.622207164764404\n",
            "Running model iteration 153\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625168323516846\n",
            "Loss: 4.606529235839844\n",
            "Running model iteration 154\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604064464569092\n",
            "Loss: 4.606797218322754\n",
            "Running model iteration 155\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589917182922363\n",
            "Loss: 4.623578071594238\n",
            "Running model iteration 156\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.580705165863037\n",
            "Loss: 4.611551761627197\n",
            "Running model iteration 157\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.584111213684082\n",
            "Loss: 4.614127159118652\n",
            "Running model iteration 158\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625425815582275\n",
            "Loss: 4.622455596923828\n",
            "Running model iteration 159\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604536533355713\n",
            "Loss: 4.605729103088379\n",
            "Running model iteration 160\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602187633514404\n",
            "Loss: 4.6104936599731445\n",
            "Running model iteration 161\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607835292816162\n",
            "Loss: 4.619089126586914\n",
            "Running model iteration 162\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613834381103516\n",
            "Loss: 4.59166145324707\n",
            "Running model iteration 163\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6162614822387695\n",
            "Loss: 4.595111846923828\n",
            "Running model iteration 164\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601413726806641\n",
            "Loss: 4.614253044128418\n",
            "Running model iteration 165\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.58519172668457\n",
            "Loss: 4.613032817840576\n",
            "Running model iteration 166\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593995571136475\n",
            "Loss: 4.615968704223633\n",
            "Running model iteration 167\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602731704711914\n",
            "Loss: 4.569033145904541\n",
            "Running model iteration 168\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605410575866699\n",
            "Loss: 4.589962959289551\n",
            "Running model iteration 169\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.636615753173828\n",
            "Loss: 4.6031599044799805\n",
            "Running model iteration 170\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589449882507324\n",
            "Loss: 4.620545864105225\n",
            "Running model iteration 171\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611202239990234\n",
            "Loss: 4.608546257019043\n",
            "Running model iteration 172\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595973968505859\n",
            "Loss: 4.606035232543945\n",
            "Running model iteration 173\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614428520202637\n",
            "Loss: 4.6346940994262695\n",
            "Running model iteration 174\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599589824676514\n",
            "Loss: 4.63194465637207\n",
            "Running model iteration 175\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621650218963623\n",
            "Loss: 4.606420040130615\n",
            "Running model iteration 176\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609780788421631\n",
            "Loss: 4.615721225738525\n",
            "Running model iteration 177\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614373207092285\n",
            "Loss: 4.610652923583984\n",
            "Running model iteration 178\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6264119148254395\n",
            "Loss: 4.615326881408691\n",
            "Running model iteration 179\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614555835723877\n",
            "Loss: 4.568674087524414\n",
            "Running model iteration 180\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614728927612305\n",
            "Loss: 4.6250457763671875\n",
            "Running model iteration 181\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613921642303467\n",
            "Loss: 4.596009254455566\n",
            "Running model iteration 182\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.626871109008789\n",
            "Loss: 4.580435752868652\n",
            "Running model iteration 183\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620763778686523\n",
            "Loss: 4.604218482971191\n",
            "Running model iteration 184\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605604648590088\n",
            "Loss: 4.610887050628662\n",
            "Running model iteration 185\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.587648391723633\n",
            "Loss: 4.623730659484863\n",
            "Running model iteration 186\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622188568115234\n",
            "Loss: 4.576577663421631\n",
            "Running model iteration 187\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.575231552124023\n",
            "Loss: 4.618971347808838\n",
            "Running model iteration 188\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601171970367432\n",
            "Loss: 4.605298042297363\n",
            "Running model iteration 189\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603215217590332\n",
            "Loss: 4.602588176727295\n",
            "Running model iteration 190\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.612697601318359\n",
            "Loss: 4.598998069763184\n",
            "Running model iteration 191\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608186721801758\n",
            "Loss: 4.627768516540527\n",
            "Running model iteration 192\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598248481750488\n",
            "Loss: 4.612284183502197\n",
            "Running model iteration 193\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61143684387207\n",
            "Loss: 4.604374885559082\n",
            "Running model iteration 194\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5925116539001465\n",
            "Loss: 4.593945503234863\n",
            "Running model iteration 195\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589241981506348\n",
            "Loss: 4.614259243011475\n",
            "Running model iteration 196\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.585086822509766\n",
            "Loss: 4.602144241333008\n",
            "Running model iteration 197\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.628798484802246\n",
            "Loss: 4.621644496917725\n",
            "Running model iteration 198\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5903849601745605\n",
            "Loss: 4.581363201141357\n",
            "Running model iteration 199\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621563911437988\n",
            "Loss: 4.595476150512695\n",
            "Running model iteration 200\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5944132804870605\n",
            "Loss: 4.607293128967285\n",
            "Running model iteration 201\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603033542633057\n",
            "Loss: 4.611155986785889\n",
            "Running model iteration 202\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602072238922119\n",
            "Loss: 4.627496719360352\n",
            "Running model iteration 203\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5910234451293945\n",
            "Loss: 4.612350940704346\n",
            "Running model iteration 204\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597009658813477\n",
            "Loss: 4.611387729644775\n",
            "Running model iteration 205\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594296455383301\n",
            "Loss: 4.614917755126953\n",
            "Running model iteration 206\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608107089996338\n",
            "Loss: 4.608069896697998\n",
            "Running model iteration 207\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618696212768555\n",
            "Loss: 4.616138458251953\n",
            "Running model iteration 208\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603124141693115\n",
            "Loss: 4.593550205230713\n",
            "Running model iteration 209\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600355625152588\n",
            "Loss: 4.600447177886963\n",
            "Running model iteration 210\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609002590179443\n",
            "Loss: 4.599151134490967\n",
            "Running model iteration 211\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59922981262207\n",
            "Loss: 4.601448059082031\n",
            "Running model iteration 212\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603509426116943\n",
            "Loss: 4.599636077880859\n",
            "Running model iteration 213\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600813388824463\n",
            "Loss: 4.5759501457214355\n",
            "Running model iteration 214\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.579736709594727\n",
            "Loss: 4.603734016418457\n",
            "Running model iteration 215\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608551979064941\n",
            "Loss: 4.589322566986084\n",
            "Running model iteration 216\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619906902313232\n",
            "Loss: 4.594148635864258\n",
            "Running model iteration 217\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601135730743408\n",
            "Loss: 4.618439674377441\n",
            "Running model iteration 218\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599028587341309\n",
            "Loss: 4.595603942871094\n",
            "Running model iteration 219\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620725631713867\n",
            "Loss: 4.5958075523376465\n",
            "Running model iteration 220\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595026016235352\n",
            "Loss: 4.609656810760498\n",
            "Running model iteration 221\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596917152404785\n",
            "Loss: 4.614718437194824\n",
            "Running model iteration 222\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601633071899414\n",
            "Loss: 4.588918209075928\n",
            "Running model iteration 223\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606805324554443\n",
            "Loss: 4.587002277374268\n",
            "Running model iteration 224\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.632508754730225\n",
            "Loss: 4.636267185211182\n",
            "Running model iteration 225\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.641611576080322\n",
            "Loss: 4.61566162109375\n",
            "Running model iteration 226\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586514949798584\n",
            "Loss: 4.604761123657227\n",
            "Running model iteration 227\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592567443847656\n",
            "Loss: 4.594310760498047\n",
            "Running model iteration 228\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60694694519043\n",
            "Loss: 4.601807117462158\n",
            "Running model iteration 229\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5868682861328125\n",
            "Loss: 4.597652435302734\n",
            "Running model iteration 230\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614312648773193\n",
            "Loss: 4.609713077545166\n",
            "Running model iteration 231\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617703914642334\n",
            "Loss: 4.608497142791748\n",
            "Running model iteration 232\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601891994476318\n",
            "Loss: 4.6185994148254395\n",
            "Running model iteration 233\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.576262474060059\n",
            "Loss: 4.594568729400635\n",
            "Running model iteration 234\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6066060066223145\n",
            "Loss: 4.621951580047607\n",
            "Running model iteration 235\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604383945465088\n",
            "Loss: 4.606236457824707\n",
            "Running model iteration 236\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606014251708984\n",
            "Loss: 4.61243200302124\n",
            "Running model iteration 237\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60243034362793\n",
            "Loss: 4.580281734466553\n",
            "Running model iteration 238\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592584609985352\n",
            "Loss: 4.58646821975708\n",
            "Running model iteration 239\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595643520355225\n",
            "Loss: 4.610811710357666\n",
            "Running model iteration 240\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591487884521484\n",
            "Loss: 4.59584379196167\n",
            "Running model iteration 241\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6262078285217285\n",
            "Loss: 4.581420421600342\n",
            "Running model iteration 242\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592100143432617\n",
            "Loss: 4.607058048248291\n",
            "Running model iteration 243\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614702224731445\n",
            "Loss: 4.604986667633057\n",
            "Running model iteration 244\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606264591217041\n",
            "Loss: 4.624854564666748\n",
            "Running model iteration 245\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622743129730225\n",
            "Loss: 4.602126121520996\n",
            "Running model iteration 246\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610952377319336\n",
            "Loss: 4.601627349853516\n",
            "Running model iteration 247\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592400074005127\n",
            "Loss: 4.605109691619873\n",
            "Running model iteration 248\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600405693054199\n",
            "Loss: 4.616372585296631\n",
            "Running model iteration 249\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622621059417725\n",
            "Loss: 4.607635498046875\n",
            "Running model iteration 250\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625214576721191\n",
            "Loss: 4.609367847442627\n",
            "Running model iteration 251\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.645929336547852\n",
            "Loss: 4.619931221008301\n",
            "Running model iteration 252\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5903778076171875\n",
            "Loss: 4.588891983032227\n",
            "Running model iteration 253\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.58711576461792\n",
            "Loss: 4.5982561111450195\n",
            "Running model iteration 254\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618404388427734\n",
            "Loss: 4.601247787475586\n",
            "Running model iteration 255\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6201019287109375\n",
            "Loss: 4.596404552459717\n",
            "Running model iteration 256\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.583611965179443\n",
            "Loss: 4.599351406097412\n",
            "Running model iteration 257\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592986583709717\n",
            "Loss: 4.59174919128418\n",
            "Running model iteration 258\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604907035827637\n",
            "Loss: 4.6286940574646\n",
            "Running model iteration 259\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610994338989258\n",
            "Loss: 4.612889289855957\n",
            "Running model iteration 260\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622901439666748\n",
            "Loss: 4.588083744049072\n",
            "Running model iteration 261\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604963779449463\n",
            "Loss: 4.575910568237305\n",
            "Running model iteration 262\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614501953125\n",
            "Loss: 4.609828948974609\n",
            "Running model iteration 263\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.627758979797363\n",
            "Loss: 4.617923259735107\n",
            "Running model iteration 264\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608182907104492\n",
            "Loss: 4.612607479095459\n",
            "Running model iteration 265\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601429462432861\n",
            "Loss: 4.617147445678711\n",
            "Running model iteration 266\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598511695861816\n",
            "Loss: 4.620916843414307\n",
            "Running model iteration 267\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625463485717773\n",
            "Loss: 4.620603084564209\n",
            "Running model iteration 268\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609932899475098\n",
            "Loss: 4.613399505615234\n",
            "Running model iteration 269\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.575112819671631\n",
            "Loss: 4.621752738952637\n",
            "Running model iteration 270\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61811637878418\n",
            "Loss: 4.615663051605225\n",
            "Running model iteration 271\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605699062347412\n",
            "Loss: 4.623159885406494\n",
            "Running model iteration 272\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5963544845581055\n",
            "Loss: 4.609584331512451\n",
            "Running model iteration 273\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59501838684082\n",
            "Loss: 4.595290184020996\n",
            "Running model iteration 274\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603509426116943\n",
            "Loss: 4.603364944458008\n",
            "Running model iteration 275\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601222038269043\n",
            "Loss: 4.603020191192627\n",
            "Running model iteration 276\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5968852043151855\n",
            "Loss: 4.599441051483154\n",
            "Running model iteration 277\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606979846954346\n",
            "Loss: 4.626150131225586\n",
            "Running model iteration 278\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6191253662109375\n",
            "Loss: 4.619585037231445\n",
            "Running model iteration 279\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618046760559082\n",
            "Loss: 4.604867935180664\n",
            "Running model iteration 280\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600431442260742\n",
            "Loss: 4.596028804779053\n",
            "Running model iteration 281\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603310585021973\n",
            "Loss: 4.624673843383789\n",
            "Running model iteration 282\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610289096832275\n",
            "Loss: 4.630893230438232\n",
            "Running model iteration 283\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599541187286377\n",
            "Loss: 4.599160671234131\n",
            "Running model iteration 284\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616281509399414\n",
            "Loss: 4.589798927307129\n",
            "Running model iteration 285\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.637812614440918\n",
            "Loss: 4.621032238006592\n",
            "Running model iteration 286\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.566821098327637\n",
            "Loss: 4.606659412384033\n",
            "Running model iteration 287\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60598611831665\n",
            "Loss: 4.597410202026367\n",
            "Running model iteration 288\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621537208557129\n",
            "Loss: 4.580002784729004\n",
            "Running model iteration 289\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606013298034668\n",
            "Loss: 4.606667995452881\n",
            "Running model iteration 290\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6217169761657715\n",
            "Loss: 4.600307464599609\n",
            "Running model iteration 291\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5952839851379395\n",
            "Loss: 4.594665050506592\n",
            "Running model iteration 292\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607938766479492\n",
            "Loss: 4.607107162475586\n",
            "Running model iteration 293\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605569839477539\n",
            "Loss: 4.604942798614502\n",
            "Running model iteration 294\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.583845615386963\n",
            "Loss: 4.581413745880127\n",
            "Running model iteration 295\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606296539306641\n",
            "Loss: 4.614871025085449\n",
            "Running model iteration 296\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595674991607666\n",
            "Loss: 4.625419616699219\n",
            "Running model iteration 297\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.576992034912109\n",
            "Loss: 4.613560199737549\n",
            "Running model iteration 298\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6351399421691895\n",
            "Loss: 4.596668720245361\n",
            "Running model iteration 299\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.590707302093506\n",
            "Loss: 4.601612091064453\n",
            "Running model iteration 300\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608782768249512\n",
            "Loss: 4.61276388168335\n",
            "Running model iteration 301\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620853900909424\n",
            "Loss: 4.588403701782227\n",
            "Running model iteration 302\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59391975402832\n",
            "Loss: 4.605661869049072\n",
            "Running model iteration 303\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.582237243652344\n",
            "Loss: 4.612268447875977\n",
            "Running model iteration 304\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.581012725830078\n",
            "Loss: 4.603251934051514\n",
            "Running model iteration 305\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608193397521973\n",
            "Loss: 4.606813430786133\n",
            "Running model iteration 306\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5784993171691895\n",
            "Loss: 4.605165004730225\n",
            "Running model iteration 307\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.585875988006592\n",
            "Loss: 4.606781005859375\n",
            "Running model iteration 308\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620140552520752\n",
            "Loss: 4.595334529876709\n",
            "Running model iteration 309\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614567279815674\n",
            "Loss: 4.627896308898926\n",
            "Running model iteration 310\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6204328536987305\n",
            "Loss: 4.6029462814331055\n",
            "Running model iteration 311\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598690509796143\n",
            "Loss: 4.616781234741211\n",
            "Running model iteration 312\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5863423347473145\n",
            "Loss: 4.581961631774902\n",
            "Running model iteration 313\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613799571990967\n",
            "Loss: 4.582007884979248\n",
            "Running model iteration 314\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601073741912842\n",
            "Loss: 4.599804878234863\n",
            "Running model iteration 315\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607193470001221\n",
            "Loss: 4.600246906280518\n",
            "Running model iteration 316\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597721576690674\n",
            "Loss: 4.634294509887695\n",
            "Running model iteration 317\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.62440299987793\n",
            "Loss: 4.6227641105651855\n",
            "Running model iteration 318\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.629018783569336\n",
            "Loss: 4.598243236541748\n",
            "Running model iteration 319\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598324775695801\n",
            "Loss: 4.6016340255737305\n",
            "Running model iteration 320\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609576225280762\n",
            "Loss: 4.614772796630859\n",
            "Running model iteration 321\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613612174987793\n",
            "Loss: 4.594228744506836\n",
            "Running model iteration 322\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607757091522217\n",
            "Loss: 4.619110584259033\n",
            "Running model iteration 323\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.612173557281494\n",
            "Loss: 4.59425687789917\n",
            "Running model iteration 324\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606494903564453\n",
            "Loss: 4.605605125427246\n",
            "Running model iteration 325\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614725589752197\n",
            "Loss: 4.610373497009277\n",
            "Running model iteration 326\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594999313354492\n",
            "Loss: 4.606992721557617\n",
            "Running model iteration 327\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598766326904297\n",
            "Loss: 4.636992931365967\n",
            "Running model iteration 328\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.624373435974121\n",
            "Loss: 4.623485565185547\n",
            "Running model iteration 329\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599629878997803\n",
            "Loss: 4.619008541107178\n",
            "Running model iteration 330\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.577781677246094\n",
            "Loss: 4.6097517013549805\n",
            "Running model iteration 331\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600356578826904\n",
            "Loss: 4.637236595153809\n",
            "Running model iteration 332\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6132612228393555\n",
            "Loss: 4.623037815093994\n",
            "Running model iteration 333\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602709770202637\n",
            "Loss: 4.631635665893555\n",
            "Running model iteration 334\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592659950256348\n",
            "Loss: 4.594273567199707\n",
            "Running model iteration 335\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600821018218994\n",
            "Loss: 4.621329307556152\n",
            "Running model iteration 336\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59505558013916\n",
            "Loss: 4.625664234161377\n",
            "Running model iteration 337\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617639541625977\n",
            "Loss: 4.627206325531006\n",
            "Running model iteration 338\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.582670211791992\n",
            "Loss: 4.629390239715576\n",
            "Running model iteration 339\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613409042358398\n",
            "Loss: 4.574099540710449\n",
            "Running model iteration 340\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6153883934021\n",
            "Loss: 4.623657703399658\n",
            "Running model iteration 341\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602530479431152\n",
            "Loss: 4.6104350090026855\n",
            "Running model iteration 342\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622858047485352\n",
            "Loss: 4.605690956115723\n",
            "Running model iteration 343\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5876922607421875\n",
            "Loss: 4.604701519012451\n",
            "Running model iteration 344\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622286796569824\n",
            "Loss: 4.6392035484313965\n",
            "Running model iteration 345\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.63514518737793\n",
            "Loss: 4.60453462600708\n",
            "Running model iteration 346\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594289302825928\n",
            "Loss: 4.595062732696533\n",
            "Running model iteration 347\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592410087585449\n",
            "Loss: 4.596962928771973\n",
            "Running model iteration 348\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596435070037842\n",
            "Loss: 4.593432903289795\n",
            "Running model iteration 349\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61235237121582\n",
            "Loss: 4.612123489379883\n",
            "Running model iteration 350\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597337245941162\n",
            "Loss: 4.57999324798584\n",
            "Running model iteration 351\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617971897125244\n",
            "Loss: 4.618387222290039\n",
            "Running model iteration 352\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60418176651001\n",
            "Loss: 4.610559463500977\n",
            "Running model iteration 353\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601690769195557\n",
            "Loss: 4.616359233856201\n",
            "Running model iteration 354\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6082258224487305\n",
            "Loss: 4.615504264831543\n",
            "Running model iteration 355\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610376358032227\n",
            "Loss: 4.635256290435791\n",
            "Running model iteration 356\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618340492248535\n",
            "Loss: 4.593144416809082\n",
            "Running model iteration 357\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609149932861328\n",
            "Loss: 4.62365198135376\n",
            "Running model iteration 358\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600319862365723\n",
            "Loss: 4.612257957458496\n",
            "Running model iteration 359\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595155239105225\n",
            "Loss: 4.586017608642578\n",
            "Running model iteration 360\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595337390899658\n",
            "Loss: 4.583218097686768\n",
            "Running model iteration 361\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5955491065979\n",
            "Loss: 4.603828430175781\n",
            "Running model iteration 362\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607208728790283\n",
            "Loss: 4.602677822113037\n",
            "Running model iteration 363\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6059393882751465\n",
            "Loss: 4.6076741218566895\n",
            "Running model iteration 364\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6120686531066895\n",
            "Loss: 4.623021125793457\n",
            "Running model iteration 365\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589089393615723\n",
            "Loss: 4.632076740264893\n",
            "Running model iteration 366\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592633247375488\n",
            "Loss: 4.591785430908203\n",
            "Running model iteration 367\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608859062194824\n",
            "Loss: 4.568808078765869\n",
            "Running model iteration 368\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604260444641113\n",
            "Loss: 4.596864223480225\n",
            "Running model iteration 369\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611593246459961\n",
            "Loss: 4.605893611907959\n",
            "Running model iteration 370\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599457740783691\n",
            "Loss: 4.5949907302856445\n",
            "Running model iteration 371\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609577178955078\n",
            "Loss: 4.584582328796387\n",
            "Running model iteration 372\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596355438232422\n",
            "Loss: 4.624983787536621\n",
            "Running model iteration 373\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591696262359619\n",
            "Loss: 4.59589147567749\n",
            "Running model iteration 374\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613306999206543\n",
            "Loss: 4.589019775390625\n",
            "Running model iteration 375\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6134724617004395\n",
            "Loss: 4.591142177581787\n",
            "Running model iteration 376\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597812652587891\n",
            "Loss: 4.615917682647705\n",
            "Running model iteration 377\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600342273712158\n",
            "Loss: 4.614627838134766\n",
            "Running model iteration 378\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603921413421631\n",
            "Loss: 4.592960357666016\n",
            "Running model iteration 379\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608808517456055\n",
            "Loss: 4.596687316894531\n",
            "Running model iteration 380\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609063148498535\n",
            "Loss: 4.593954086303711\n",
            "Running model iteration 381\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610980033874512\n",
            "Loss: 4.590446472167969\n",
            "Running model iteration 382\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596674919128418\n",
            "Loss: 4.60958194732666\n",
            "Running model iteration 383\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.584629058837891\n",
            "Loss: 4.596367359161377\n",
            "Running model iteration 384\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592587471008301\n",
            "Loss: 4.6165618896484375\n",
            "Running model iteration 385\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614290237426758\n",
            "Loss: 4.586945056915283\n",
            "Running model iteration 386\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6003522872924805\n",
            "Loss: 4.594092845916748\n",
            "Running model iteration 387\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.628473281860352\n",
            "Loss: 4.6315741539001465\n",
            "Running model iteration 388\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608906269073486\n",
            "Loss: 4.599111557006836\n",
            "Running model iteration 389\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597594261169434\n",
            "Loss: 4.604650974273682\n",
            "Running model iteration 390\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607023239135742\n",
            "Loss: 4.6225690841674805\n",
            "Running model iteration 391\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59145975112915\n",
            "Loss: 4.585415363311768\n",
            "Running model iteration 392\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588533878326416\n",
            "Loss: 4.598124027252197\n",
            "Running model iteration 393\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606795787811279\n",
            "Loss: 4.58668327331543\n",
            "Running model iteration 394\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605061054229736\n",
            "Loss: 4.613483905792236\n",
            "Running model iteration 395\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60270357131958\n",
            "Loss: 4.628011703491211\n",
            "Running model iteration 396\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601311683654785\n",
            "Loss: 4.6138691902160645\n",
            "Running model iteration 397\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607785224914551\n",
            "Loss: 4.59071159362793\n",
            "Running model iteration 398\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.646430492401123\n",
            "Loss: 4.608885288238525\n",
            "Running model iteration 399\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61561393737793\n",
            "Loss: 4.628332138061523\n",
            "Running model iteration 400\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611830234527588\n",
            "Loss: 4.6105732917785645\n",
            "Running model iteration 401\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591659069061279\n",
            "Loss: 4.605969429016113\n",
            "Running model iteration 402\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.639368057250977\n",
            "Loss: 4.586418628692627\n",
            "Running model iteration 403\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.633018970489502\n",
            "Loss: 4.617091655731201\n",
            "Running model iteration 404\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.636748790740967\n",
            "Loss: 4.616403579711914\n",
            "Running model iteration 405\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591085433959961\n",
            "Loss: 4.581557750701904\n",
            "Running model iteration 406\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.631176948547363\n",
            "Loss: 4.613646030426025\n",
            "Running model iteration 407\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619817733764648\n",
            "Loss: 4.6073808670043945\n",
            "Running model iteration 408\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613104343414307\n",
            "Loss: 4.608118534088135\n",
            "Running model iteration 409\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592812538146973\n",
            "Loss: 4.598145961761475\n",
            "Running model iteration 410\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610867977142334\n",
            "Loss: 4.5918474197387695\n",
            "Running model iteration 411\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60914421081543\n",
            "Loss: 4.592505931854248\n",
            "Running model iteration 412\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621434688568115\n",
            "Loss: 4.594207286834717\n",
            "Running model iteration 413\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611447334289551\n",
            "Loss: 4.599069595336914\n",
            "Running model iteration 414\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5965800285339355\n",
            "Loss: 4.604806423187256\n",
            "Running model iteration 415\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602434158325195\n",
            "Loss: 4.607152938842773\n",
            "Running model iteration 416\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.612732887268066\n",
            "Loss: 4.594440460205078\n",
            "Running model iteration 417\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595119476318359\n",
            "Loss: 4.620066165924072\n",
            "Running model iteration 418\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.584171295166016\n",
            "Loss: 4.595342636108398\n",
            "Running model iteration 419\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603872299194336\n",
            "Loss: 4.609085559844971\n",
            "Running model iteration 420\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595799446105957\n",
            "Loss: 4.598759651184082\n",
            "Running model iteration 421\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617401599884033\n",
            "Loss: 4.595362186431885\n",
            "Running model iteration 422\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589852333068848\n",
            "Loss: 4.59175443649292\n",
            "Running model iteration 423\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600270748138428\n",
            "Loss: 4.593988418579102\n",
            "Running model iteration 424\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61465311050415\n",
            "Loss: 4.592321872711182\n",
            "Running model iteration 425\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616884708404541\n",
            "Loss: 4.605216026306152\n",
            "Running model iteration 426\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5886945724487305\n",
            "Loss: 4.628838062286377\n",
            "Running model iteration 427\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611880302429199\n",
            "Loss: 4.609963417053223\n",
            "Running model iteration 428\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611763954162598\n",
            "Loss: 4.613341808319092\n",
            "Running model iteration 429\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611942291259766\n",
            "Loss: 4.622532367706299\n",
            "Running model iteration 430\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602044105529785\n",
            "Loss: 4.597037315368652\n",
            "Running model iteration 431\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588973045349121\n",
            "Loss: 4.6317877769470215\n",
            "Running model iteration 432\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610774517059326\n",
            "Loss: 4.58820915222168\n",
            "Running model iteration 433\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591129302978516\n",
            "Loss: 4.602781772613525\n",
            "Running model iteration 434\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605532646179199\n",
            "Loss: 4.607238292694092\n",
            "Running model iteration 435\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6028056144714355\n",
            "Loss: 4.599796295166016\n",
            "Running model iteration 436\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609981060028076\n",
            "Loss: 4.629168510437012\n",
            "Running model iteration 437\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6038007736206055\n",
            "Loss: 4.609770774841309\n",
            "Running model iteration 438\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.587137222290039\n",
            "Loss: 4.625565052032471\n",
            "Running model iteration 439\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596106052398682\n",
            "Loss: 4.601596832275391\n",
            "Running model iteration 440\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598818778991699\n",
            "Loss: 4.611701488494873\n",
            "Running model iteration 441\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603410243988037\n",
            "Loss: 4.598688125610352\n",
            "Running model iteration 442\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600541591644287\n",
            "Loss: 4.606597423553467\n",
            "Running model iteration 443\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607554912567139\n",
            "Loss: 4.607583999633789\n",
            "Running model iteration 444\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586703300476074\n",
            "Loss: 4.620934009552002\n",
            "Running model iteration 445\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.624434947967529\n",
            "Loss: 4.600836277008057\n",
            "Running model iteration 446\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609306335449219\n",
            "Loss: 4.607488632202148\n",
            "Running model iteration 447\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.627889633178711\n",
            "Loss: 4.619594573974609\n",
            "Running model iteration 448\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60437536239624\n",
            "Loss: 4.608197212219238\n",
            "Running model iteration 449\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610820770263672\n",
            "Loss: 4.6162824630737305\n",
            "Running model iteration 450\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608754634857178\n",
            "Loss: 4.588763236999512\n",
            "Running model iteration 451\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609928131103516\n",
            "Loss: 4.592792510986328\n",
            "Running model iteration 452\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609512805938721\n",
            "Loss: 4.640514373779297\n",
            "Running model iteration 453\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592319488525391\n",
            "Loss: 4.61923360824585\n",
            "Running model iteration 454\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6067795753479\n",
            "Loss: 4.616471767425537\n",
            "Running model iteration 455\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608090400695801\n",
            "Loss: 4.597801685333252\n",
            "Running model iteration 456\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61219596862793\n",
            "Loss: 4.590532302856445\n",
            "Running model iteration 457\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59469747543335\n",
            "Loss: 4.604528427124023\n",
            "Running model iteration 458\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594049453735352\n",
            "Loss: 4.598336696624756\n",
            "Running model iteration 459\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.627481937408447\n",
            "Loss: 4.599287033081055\n",
            "Running model iteration 460\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602443695068359\n",
            "Loss: 4.614752292633057\n",
            "Running model iteration 461\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6089701652526855\n",
            "Loss: 4.616653919219971\n",
            "Running model iteration 462\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609533786773682\n",
            "Loss: 4.625746250152588\n",
            "Running model iteration 463\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.623690605163574\n",
            "Loss: 4.580982208251953\n",
            "Running model iteration 464\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586623668670654\n",
            "Loss: 4.628396511077881\n",
            "Running model iteration 465\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610461235046387\n",
            "Loss: 4.597708225250244\n",
            "Running model iteration 466\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622750759124756\n",
            "Loss: 4.607011318206787\n",
            "Running model iteration 467\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.629653453826904\n",
            "Loss: 4.629654407501221\n",
            "Running model iteration 468\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600604057312012\n",
            "Loss: 4.5916032791137695\n",
            "Running model iteration 469\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.612221717834473\n",
            "Loss: 4.604696750640869\n",
            "Running model iteration 470\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619601249694824\n",
            "Loss: 4.5985941886901855\n",
            "Running model iteration 471\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618608474731445\n",
            "Loss: 4.623669147491455\n",
            "Running model iteration 472\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619515419006348\n",
            "Loss: 4.584062099456787\n",
            "Running model iteration 473\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.623785972595215\n",
            "Loss: 4.603939056396484\n",
            "Running model iteration 474\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.62660026550293\n",
            "Loss: 4.594893932342529\n",
            "Running model iteration 475\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6287641525268555\n",
            "Loss: 4.615053653717041\n",
            "Running model iteration 476\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595714569091797\n",
            "Loss: 4.616624355316162\n",
            "Running model iteration 477\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.587458610534668\n",
            "Loss: 4.610395908355713\n",
            "Running model iteration 478\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6028666496276855\n",
            "Loss: 4.597386360168457\n",
            "Running model iteration 479\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602490425109863\n",
            "Loss: 4.610766410827637\n",
            "Running model iteration 480\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6027421951293945\n",
            "Loss: 4.611335277557373\n",
            "Running model iteration 481\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.57016134262085\n",
            "Loss: 4.621567249298096\n",
            "Running model iteration 482\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.615305423736572\n",
            "Loss: 4.598450183868408\n",
            "Running model iteration 483\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609507083892822\n",
            "Loss: 4.620544910430908\n",
            "Running model iteration 484\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600705146789551\n",
            "Loss: 4.611344337463379\n",
            "Running model iteration 485\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.581310272216797\n",
            "Loss: 4.596151351928711\n",
            "Running model iteration 486\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596493721008301\n",
            "Loss: 4.616006851196289\n",
            "Running model iteration 487\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609188079833984\n",
            "Loss: 4.613397121429443\n",
            "Running model iteration 488\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613925933837891\n",
            "Loss: 4.586357593536377\n",
            "Running model iteration 489\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586818695068359\n",
            "Loss: 4.6028733253479\n",
            "Running model iteration 490\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599369049072266\n",
            "Loss: 4.624894618988037\n",
            "Running model iteration 491\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601986408233643\n",
            "Loss: 4.585201263427734\n",
            "Running model iteration 492\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.585028171539307\n",
            "Loss: 4.6119384765625\n",
            "Running model iteration 493\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592356204986572\n",
            "Loss: 4.611635684967041\n",
            "Running model iteration 494\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604842185974121\n",
            "Loss: 4.613528251647949\n",
            "Running model iteration 495\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586993217468262\n",
            "Loss: 4.593867778778076\n",
            "Running model iteration 496\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604098320007324\n",
            "Loss: 4.618175506591797\n",
            "Running model iteration 497\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588418483734131\n",
            "Loss: 4.612222194671631\n",
            "Running model iteration 498\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603275299072266\n",
            "Loss: 4.589231491088867\n",
            "Running model iteration 499\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61949348449707\n",
            "Loss: 4.610276699066162\n",
            "Running model iteration 500\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602560520172119\n",
            "Loss: 4.622955799102783\n",
            "Running model iteration 501\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.582484722137451\n",
            "Loss: 4.603918075561523\n",
            "Running model iteration 502\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588602542877197\n",
            "Loss: 4.589897632598877\n",
            "Running model iteration 503\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61230993270874\n",
            "Loss: 4.606203556060791\n",
            "Running model iteration 504\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61062479019165\n",
            "Loss: 4.610818386077881\n",
            "Running model iteration 505\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.571891784667969\n",
            "Loss: 4.587069511413574\n",
            "Running model iteration 506\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596341133117676\n",
            "Loss: 4.603219509124756\n",
            "Running model iteration 507\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.624662399291992\n",
            "Loss: 4.599935054779053\n",
            "Running model iteration 508\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595155239105225\n",
            "Loss: 4.595642566680908\n",
            "Running model iteration 509\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597671985626221\n",
            "Loss: 4.597276210784912\n",
            "Running model iteration 510\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614860534667969\n",
            "Loss: 4.599157333374023\n",
            "Running model iteration 511\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616470813751221\n",
            "Loss: 4.586977958679199\n",
            "Running model iteration 512\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603204727172852\n",
            "Loss: 4.5896220207214355\n",
            "Running model iteration 513\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597210884094238\n",
            "Loss: 4.608639717102051\n",
            "Running model iteration 514\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.570352554321289\n",
            "Loss: 4.603525161743164\n",
            "Running model iteration 515\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59218692779541\n",
            "Loss: 4.619571685791016\n",
            "Running model iteration 516\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.634701251983643\n",
            "Loss: 4.618145942687988\n",
            "Running model iteration 517\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588746547698975\n",
            "Loss: 4.5958662033081055\n",
            "Running model iteration 518\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592973232269287\n",
            "Loss: 4.613193511962891\n",
            "Running model iteration 519\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6083455085754395\n",
            "Loss: 4.564892292022705\n",
            "Running model iteration 520\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595126152038574\n",
            "Loss: 4.614210605621338\n",
            "Running model iteration 521\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5941853523254395\n",
            "Loss: 4.605341911315918\n",
            "Running model iteration 522\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60920524597168\n",
            "Loss: 4.5939555168151855\n",
            "Running model iteration 523\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.623882293701172\n",
            "Loss: 4.619091987609863\n",
            "Running model iteration 524\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622859954833984\n",
            "Loss: 4.5826873779296875\n",
            "Running model iteration 525\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616134166717529\n",
            "Loss: 4.591269493103027\n",
            "Running model iteration 526\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.58259391784668\n",
            "Loss: 4.592695713043213\n",
            "Running model iteration 527\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.626847743988037\n",
            "Loss: 4.611958980560303\n",
            "Running model iteration 528\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.584033489227295\n",
            "Loss: 4.607621669769287\n",
            "Running model iteration 529\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.623303413391113\n",
            "Loss: 4.6116814613342285\n",
            "Running model iteration 530\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.639657020568848\n",
            "Loss: 4.622399806976318\n",
            "Running model iteration 531\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607532501220703\n",
            "Loss: 4.60900354385376\n",
            "Running model iteration 532\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586729049682617\n",
            "Loss: 4.593608379364014\n",
            "Running model iteration 533\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620169162750244\n",
            "Loss: 4.6072773933410645\n",
            "Running model iteration 534\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600241184234619\n",
            "Loss: 4.621539115905762\n",
            "Running model iteration 535\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609048843383789\n",
            "Loss: 4.604682922363281\n",
            "Running model iteration 536\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596716403961182\n",
            "Loss: 4.587302207946777\n",
            "Running model iteration 537\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594723701477051\n",
            "Loss: 4.583219528198242\n",
            "Running model iteration 538\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.587966442108154\n",
            "Loss: 4.615871429443359\n",
            "Running model iteration 539\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591017723083496\n",
            "Loss: 4.622190952301025\n",
            "Running model iteration 540\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621218681335449\n",
            "Loss: 4.613351345062256\n",
            "Running model iteration 541\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.583249092102051\n",
            "Loss: 4.596261978149414\n",
            "Running model iteration 542\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5983662605285645\n",
            "Loss: 4.609848499298096\n",
            "Running model iteration 543\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604860305786133\n",
            "Loss: 4.600822925567627\n",
            "Running model iteration 544\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597471714019775\n",
            "Loss: 4.613475799560547\n",
            "Running model iteration 545\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597738265991211\n",
            "Loss: 4.615643501281738\n",
            "Running model iteration 546\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589550018310547\n",
            "Loss: 4.602051258087158\n",
            "Running model iteration 547\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602802276611328\n",
            "Loss: 4.586388111114502\n",
            "Running model iteration 548\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607739448547363\n",
            "Loss: 4.588306903839111\n",
            "Running model iteration 549\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593856334686279\n",
            "Loss: 4.595198154449463\n",
            "Running model iteration 550\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601262092590332\n",
            "Loss: 4.601015090942383\n",
            "Running model iteration 551\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597126007080078\n",
            "Loss: 4.619822025299072\n",
            "Running model iteration 552\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.581172943115234\n",
            "Loss: 4.58635139465332\n",
            "Running model iteration 553\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6503376960754395\n",
            "Loss: 4.641859531402588\n",
            "Running model iteration 554\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586787223815918\n",
            "Loss: 4.605882167816162\n",
            "Running model iteration 555\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611745357513428\n",
            "Loss: 4.6222639083862305\n",
            "Running model iteration 556\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609163284301758\n",
            "Loss: 4.600442409515381\n",
            "Running model iteration 557\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.577526569366455\n",
            "Loss: 4.608462333679199\n",
            "Running model iteration 558\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5950236320495605\n",
            "Loss: 4.60174036026001\n",
            "Running model iteration 559\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598622798919678\n",
            "Loss: 4.598245143890381\n",
            "Running model iteration 560\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614529609680176\n",
            "Loss: 4.614959716796875\n",
            "Running model iteration 561\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595048427581787\n",
            "Loss: 4.5916852951049805\n",
            "Running model iteration 562\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6168107986450195\n",
            "Loss: 4.621194839477539\n",
            "Running model iteration 563\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6058454513549805\n",
            "Loss: 4.589601039886475\n",
            "Running model iteration 564\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594057559967041\n",
            "Loss: 4.618700981140137\n",
            "Running model iteration 565\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.612430095672607\n",
            "Loss: 4.633551120758057\n",
            "Running model iteration 566\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.587778091430664\n",
            "Loss: 4.618514537811279\n",
            "Running model iteration 567\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597073554992676\n",
            "Loss: 4.60379695892334\n",
            "Running model iteration 568\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593451499938965\n",
            "Loss: 4.609541893005371\n",
            "Running model iteration 569\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609895706176758\n",
            "Loss: 4.612562656402588\n",
            "Running model iteration 570\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588990688323975\n",
            "Loss: 4.592891693115234\n",
            "Running model iteration 571\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619346618652344\n",
            "Loss: 4.5972065925598145\n",
            "Running model iteration 572\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.615584373474121\n",
            "Loss: 4.611959934234619\n",
            "Running model iteration 573\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597604751586914\n",
            "Loss: 4.6038126945495605\n",
            "Running model iteration 574\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592313766479492\n",
            "Loss: 4.614379405975342\n",
            "Running model iteration 575\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6124348640441895\n",
            "Loss: 4.598040580749512\n",
            "Running model iteration 576\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607661247253418\n",
            "Loss: 4.582400321960449\n",
            "Running model iteration 577\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6082000732421875\n",
            "Loss: 4.621115207672119\n",
            "Running model iteration 578\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602268695831299\n",
            "Loss: 4.590696811676025\n",
            "Running model iteration 579\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593105316162109\n",
            "Loss: 4.578081130981445\n",
            "Running model iteration 580\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599005699157715\n",
            "Loss: 4.630302429199219\n",
            "Running model iteration 581\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.627568244934082\n",
            "Loss: 4.61520528793335\n",
            "Running model iteration 582\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60745096206665\n",
            "Loss: 4.600825309753418\n",
            "Running model iteration 583\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604961395263672\n",
            "Loss: 4.6265482902526855\n",
            "Running model iteration 584\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605188369750977\n",
            "Loss: 4.609414577484131\n",
            "Running model iteration 585\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6147332191467285\n",
            "Loss: 4.589449882507324\n",
            "Running model iteration 586\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589754104614258\n",
            "Loss: 4.630376815795898\n",
            "Running model iteration 587\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605721950531006\n",
            "Loss: 4.616462230682373\n",
            "Running model iteration 588\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609999656677246\n",
            "Loss: 4.595041275024414\n",
            "Running model iteration 589\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5894670486450195\n",
            "Loss: 4.605635166168213\n",
            "Running model iteration 590\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618311882019043\n",
            "Loss: 4.6033616065979\n",
            "Running model iteration 591\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.626867771148682\n",
            "Loss: 4.611871242523193\n",
            "Running model iteration 592\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5933003425598145\n",
            "Loss: 4.614369869232178\n",
            "Running model iteration 593\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599421501159668\n",
            "Loss: 4.622636795043945\n",
            "Running model iteration 594\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.626694679260254\n",
            "Loss: 4.6121416091918945\n",
            "Running model iteration 595\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598865032196045\n",
            "Loss: 4.597198963165283\n",
            "Running model iteration 596\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6052751541137695\n",
            "Loss: 4.631099700927734\n",
            "Running model iteration 597\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610820770263672\n",
            "Loss: 4.619329452514648\n",
            "Running model iteration 598\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.576552867889404\n",
            "Loss: 4.611605644226074\n",
            "Running model iteration 599\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614630222320557\n",
            "Loss: 4.615982532501221\n",
            "Running model iteration 600\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601862907409668\n",
            "Loss: 4.614367485046387\n",
            "Running model iteration 601\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598056793212891\n",
            "Loss: 4.618940353393555\n",
            "Running model iteration 602\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597578048706055\n",
            "Loss: 4.590103626251221\n",
            "Running model iteration 603\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602024078369141\n",
            "Loss: 4.6251349449157715\n",
            "Running model iteration 604\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61585807800293\n",
            "Loss: 4.624446868896484\n",
            "Running model iteration 605\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.615156173706055\n",
            "Loss: 4.6256256103515625\n",
            "Running model iteration 606\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610043048858643\n",
            "Loss: 4.5948166847229\n",
            "Running model iteration 607\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601928234100342\n",
            "Loss: 4.594908237457275\n",
            "Running model iteration 608\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603928089141846\n",
            "Loss: 4.591699600219727\n",
            "Running model iteration 609\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606905460357666\n",
            "Loss: 4.598817348480225\n",
            "Running model iteration 610\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602831840515137\n",
            "Loss: 4.622323513031006\n",
            "Running model iteration 611\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589601993560791\n",
            "Loss: 4.610601425170898\n",
            "Running model iteration 612\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.612273693084717\n",
            "Loss: 4.622451305389404\n",
            "Running model iteration 613\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598367214202881\n",
            "Loss: 4.584200382232666\n",
            "Running model iteration 614\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606138706207275\n",
            "Loss: 4.606788635253906\n",
            "Running model iteration 615\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602819919586182\n",
            "Loss: 4.563776969909668\n",
            "Running model iteration 616\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610605716705322\n",
            "Loss: 4.607381343841553\n",
            "Running model iteration 617\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604429721832275\n",
            "Loss: 4.596200942993164\n",
            "Running model iteration 618\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.596724987030029\n",
            "Loss: 4.592444896697998\n",
            "Running model iteration 619\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597266674041748\n",
            "Loss: 4.6254401206970215\n",
            "Running model iteration 620\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598028659820557\n",
            "Loss: 4.594672679901123\n",
            "Running model iteration 621\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597448348999023\n",
            "Loss: 4.586319923400879\n",
            "Running model iteration 622\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604022026062012\n",
            "Loss: 4.602565765380859\n",
            "Running model iteration 623\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616517066955566\n",
            "Loss: 4.588278293609619\n",
            "Running model iteration 624\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59727668762207\n",
            "Loss: 4.622018814086914\n",
            "Running model iteration 625\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625753879547119\n",
            "Loss: 4.636496067047119\n",
            "Running model iteration 626\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604318618774414\n",
            "Loss: 4.599635124206543\n",
            "Running model iteration 627\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604650974273682\n",
            "Loss: 4.616132736206055\n",
            "Running model iteration 628\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620138168334961\n",
            "Loss: 4.629672527313232\n",
            "Running model iteration 629\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589666843414307\n",
            "Loss: 4.606875419616699\n",
            "Running model iteration 630\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618494987487793\n",
            "Loss: 4.6399149894714355\n",
            "Running model iteration 631\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.587375640869141\n",
            "Loss: 4.599961280822754\n",
            "Running model iteration 632\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610259532928467\n",
            "Loss: 4.611608982086182\n",
            "Running model iteration 633\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.587761402130127\n",
            "Loss: 4.59985876083374\n",
            "Running model iteration 634\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6032023429870605\n",
            "Loss: 4.599595546722412\n",
            "Running model iteration 635\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6149187088012695\n",
            "Loss: 4.621337413787842\n",
            "Running model iteration 636\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608967304229736\n",
            "Loss: 4.609215259552002\n",
            "Running model iteration 637\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611801624298096\n",
            "Loss: 4.5852274894714355\n",
            "Running model iteration 638\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.635198593139648\n",
            "Loss: 4.604742050170898\n",
            "Running model iteration 639\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610983371734619\n",
            "Loss: 4.630867004394531\n",
            "Running model iteration 640\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.611677646636963\n",
            "Loss: 4.633965015411377\n",
            "Running model iteration 641\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597972393035889\n",
            "Loss: 4.601654529571533\n",
            "Running model iteration 642\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.581808567047119\n",
            "Loss: 4.611783027648926\n",
            "Running model iteration 643\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586071491241455\n",
            "Loss: 4.5934553146362305\n",
            "Running model iteration 644\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.634265899658203\n",
            "Loss: 4.624019622802734\n",
            "Running model iteration 645\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605053901672363\n",
            "Loss: 4.606626987457275\n",
            "Running model iteration 646\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589317798614502\n",
            "Loss: 4.579127311706543\n",
            "Running model iteration 647\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5965800285339355\n",
            "Loss: 4.606738090515137\n",
            "Running model iteration 648\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.62313985824585\n",
            "Loss: 4.612987995147705\n",
            "Running model iteration 649\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59435510635376\n",
            "Loss: 4.623660564422607\n",
            "Running model iteration 650\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.59113073348999\n",
            "Loss: 4.597134590148926\n",
            "Running model iteration 651\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61732292175293\n",
            "Loss: 4.598864555358887\n",
            "Running model iteration 652\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601567268371582\n",
            "Loss: 4.619882106781006\n",
            "Running model iteration 653\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6228132247924805\n",
            "Loss: 4.5883965492248535\n",
            "Running model iteration 654\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594110488891602\n",
            "Loss: 4.609912872314453\n",
            "Running model iteration 655\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5927815437316895\n",
            "Loss: 4.568290710449219\n",
            "Running model iteration 656\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.588874816894531\n",
            "Loss: 4.624468803405762\n",
            "Running model iteration 657\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608238697052002\n",
            "Loss: 4.6232380867004395\n",
            "Running model iteration 658\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619635581970215\n",
            "Loss: 4.624341011047363\n",
            "Running model iteration 659\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599628925323486\n",
            "Loss: 4.611714839935303\n",
            "Running model iteration 660\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6319074630737305\n",
            "Loss: 4.5937933921813965\n",
            "Running model iteration 661\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.582031726837158\n",
            "Loss: 4.609720706939697\n",
            "Running model iteration 662\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613315105438232\n",
            "Loss: 4.592955112457275\n",
            "Running model iteration 663\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618865966796875\n",
            "Loss: 4.583578109741211\n",
            "Running model iteration 664\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610042572021484\n",
            "Loss: 4.592144966125488\n",
            "Running model iteration 665\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607341766357422\n",
            "Loss: 4.584533214569092\n",
            "Running model iteration 666\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605727195739746\n",
            "Loss: 4.618217945098877\n",
            "Running model iteration 667\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601778507232666\n",
            "Loss: 4.606504917144775\n",
            "Running model iteration 668\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618066310882568\n",
            "Loss: 4.592218399047852\n",
            "Running model iteration 669\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600687026977539\n",
            "Loss: 4.609772205352783\n",
            "Running model iteration 670\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616531848907471\n",
            "Loss: 4.5909576416015625\n",
            "Running model iteration 671\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6054205894470215\n",
            "Loss: 4.605898857116699\n",
            "Running model iteration 672\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613228797912598\n",
            "Loss: 4.634712219238281\n",
            "Running model iteration 673\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.641977310180664\n",
            "Loss: 4.602133750915527\n",
            "Running model iteration 674\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.615950107574463\n",
            "Loss: 4.580073833465576\n",
            "Running model iteration 675\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602969169616699\n",
            "Loss: 4.592832565307617\n",
            "Running model iteration 676\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6099324226379395\n",
            "Loss: 4.6126017570495605\n",
            "Running model iteration 677\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.626465797424316\n",
            "Loss: 4.627532005310059\n",
            "Running model iteration 678\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617810249328613\n",
            "Loss: 4.6119585037231445\n",
            "Running model iteration 679\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599413871765137\n",
            "Loss: 4.586014270782471\n",
            "Running model iteration 680\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618556022644043\n",
            "Loss: 4.630501747131348\n",
            "Running model iteration 681\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619279861450195\n",
            "Loss: 4.6085710525512695\n",
            "Running model iteration 682\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.594907760620117\n",
            "Loss: 4.585932731628418\n",
            "Running model iteration 683\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60917329788208\n",
            "Loss: 4.6066179275512695\n",
            "Running model iteration 684\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.604962348937988\n",
            "Loss: 4.600985527038574\n",
            "Running model iteration 685\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603646755218506\n",
            "Loss: 4.612045764923096\n",
            "Running model iteration 686\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608806133270264\n",
            "Loss: 4.598740100860596\n",
            "Running model iteration 687\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610074996948242\n",
            "Loss: 4.581536293029785\n",
            "Running model iteration 688\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.636033058166504\n",
            "Loss: 4.591967582702637\n",
            "Running model iteration 689\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603196620941162\n",
            "Loss: 4.587037086486816\n",
            "Running model iteration 690\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5952277183532715\n",
            "Loss: 4.598557949066162\n",
            "Running model iteration 691\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600890159606934\n",
            "Loss: 4.611024856567383\n",
            "Running model iteration 692\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606565952301025\n",
            "Loss: 4.607376575469971\n",
            "Running model iteration 693\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619599342346191\n",
            "Loss: 4.611677169799805\n",
            "Running model iteration 694\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593479156494141\n",
            "Loss: 4.634232997894287\n",
            "Running model iteration 695\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593857765197754\n",
            "Loss: 4.59031343460083\n",
            "Running model iteration 696\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591710567474365\n",
            "Loss: 4.601315975189209\n",
            "Running model iteration 697\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602597713470459\n",
            "Loss: 4.597090244293213\n",
            "Running model iteration 698\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6034135818481445\n",
            "Loss: 4.607520580291748\n",
            "Running model iteration 699\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621974945068359\n",
            "Loss: 4.588159561157227\n",
            "Running model iteration 700\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608250617980957\n",
            "Loss: 4.574653148651123\n",
            "Running model iteration 701\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619284629821777\n",
            "Loss: 4.585451602935791\n",
            "Running model iteration 702\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620548248291016\n",
            "Loss: 4.604733467102051\n",
            "Running model iteration 703\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607346534729004\n",
            "Loss: 4.583962917327881\n",
            "Running model iteration 704\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.63294792175293\n",
            "Loss: 4.6246113777160645\n",
            "Running model iteration 705\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.635149955749512\n",
            "Loss: 4.615747451782227\n",
            "Running model iteration 706\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6164326667785645\n",
            "Loss: 4.599370002746582\n",
            "Running model iteration 707\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6189351081848145\n",
            "Loss: 4.610546112060547\n",
            "Running model iteration 708\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589321136474609\n",
            "Loss: 4.593451499938965\n",
            "Running model iteration 709\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586101055145264\n",
            "Loss: 4.603404998779297\n",
            "Running model iteration 710\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5963239669799805\n",
            "Loss: 4.607387542724609\n",
            "Running model iteration 711\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.590969085693359\n",
            "Loss: 4.612576484680176\n",
            "Running model iteration 712\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593515396118164\n",
            "Loss: 4.591169357299805\n",
            "Running model iteration 713\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.618542194366455\n",
            "Loss: 4.605648994445801\n",
            "Running model iteration 714\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.589508533477783\n",
            "Loss: 4.624199390411377\n",
            "Running model iteration 715\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600935459136963\n",
            "Loss: 4.628231525421143\n",
            "Running model iteration 716\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.64827299118042\n",
            "Loss: 4.601008892059326\n",
            "Running model iteration 717\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605196475982666\n",
            "Loss: 4.595260143280029\n",
            "Running model iteration 718\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614140510559082\n",
            "Loss: 4.611283779144287\n",
            "Running model iteration 719\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598541736602783\n",
            "Loss: 4.585178375244141\n",
            "Running model iteration 720\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591796398162842\n",
            "Loss: 4.61833381652832\n",
            "Running model iteration 721\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606386184692383\n",
            "Loss: 4.6091227531433105\n",
            "Running model iteration 722\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595785617828369\n",
            "Loss: 4.6068291664123535\n",
            "Running model iteration 723\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.591131210327148\n",
            "Loss: 4.609054088592529\n",
            "Running model iteration 724\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605958938598633\n",
            "Loss: 4.613706588745117\n",
            "Running model iteration 725\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.619014739990234\n",
            "Loss: 4.609053134918213\n",
            "Running model iteration 726\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.627349376678467\n",
            "Loss: 4.611947059631348\n",
            "Running model iteration 727\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6136393547058105\n",
            "Loss: 4.593782424926758\n",
            "Running model iteration 728\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.631631851196289\n",
            "Loss: 4.610960483551025\n",
            "Running model iteration 729\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5967183113098145\n",
            "Loss: 4.598197937011719\n",
            "Running model iteration 730\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.578784942626953\n",
            "Loss: 4.609386920928955\n",
            "Running model iteration 731\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.593290328979492\n",
            "Loss: 4.638051986694336\n",
            "Running model iteration 732\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6157331466674805\n",
            "Loss: 4.619677543640137\n",
            "Running model iteration 733\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614843368530273\n",
            "Loss: 4.615577220916748\n",
            "Running model iteration 734\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607493877410889\n",
            "Loss: 4.588836193084717\n",
            "Running model iteration 735\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621140956878662\n",
            "Loss: 4.60585355758667\n",
            "Running model iteration 736\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6282758712768555\n",
            "Loss: 4.629525661468506\n",
            "Running model iteration 737\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614826679229736\n",
            "Loss: 4.593711853027344\n",
            "Running model iteration 738\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.574742317199707\n",
            "Loss: 4.601629257202148\n",
            "Running model iteration 739\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.620691299438477\n",
            "Loss: 4.615431308746338\n",
            "Running model iteration 740\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.614389419555664\n",
            "Loss: 4.6290507316589355\n",
            "Running model iteration 741\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605727672576904\n",
            "Loss: 4.605080604553223\n",
            "Running model iteration 742\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.587275981903076\n",
            "Loss: 4.621526718139648\n",
            "Running model iteration 743\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.617715358734131\n",
            "Loss: 4.612911224365234\n",
            "Running model iteration 744\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.592391014099121\n",
            "Loss: 4.601933002471924\n",
            "Running model iteration 745\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602733135223389\n",
            "Loss: 4.615140914916992\n",
            "Running model iteration 746\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6015305519104\n",
            "Loss: 4.595582008361816\n",
            "Running model iteration 747\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608398914337158\n",
            "Loss: 4.605070114135742\n",
            "Running model iteration 748\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5810227394104\n",
            "Loss: 4.617337703704834\n",
            "Running model iteration 749\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610567092895508\n",
            "Loss: 4.604963302612305\n",
            "Running model iteration 750\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.582828521728516\n",
            "Loss: 4.622344493865967\n",
            "Running model iteration 751\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.577287673950195\n",
            "Loss: 4.609226226806641\n",
            "Running model iteration 752\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603707790374756\n",
            "Loss: 4.598559856414795\n",
            "Running model iteration 753\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.624383926391602\n",
            "Loss: 4.607646942138672\n",
            "Running model iteration 754\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625492095947266\n",
            "Loss: 4.601021766662598\n",
            "Running model iteration 755\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613302230834961\n",
            "Loss: 4.579527378082275\n",
            "Running model iteration 756\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602016448974609\n",
            "Loss: 4.605396747589111\n",
            "Running model iteration 757\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598667144775391\n",
            "Loss: 4.606565952301025\n",
            "Running model iteration 758\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.603029727935791\n",
            "Loss: 4.63125467300415\n",
            "Running model iteration 759\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610947132110596\n",
            "Loss: 4.589898109436035\n",
            "Running model iteration 760\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.612222194671631\n",
            "Loss: 4.605966567993164\n",
            "Running model iteration 761\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.586824417114258\n",
            "Loss: 4.613312721252441\n",
            "Running model iteration 762\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.602076530456543\n",
            "Loss: 4.5931715965271\n",
            "Running model iteration 763\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.590346813201904\n",
            "Loss: 4.596926212310791\n",
            "Running model iteration 764\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.605306625366211\n",
            "Loss: 4.6237640380859375\n",
            "Running model iteration 765\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607812404632568\n",
            "Loss: 4.620941638946533\n",
            "Running model iteration 766\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.624313831329346\n",
            "Loss: 4.5936431884765625\n",
            "Running model iteration 767\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.601712226867676\n",
            "Loss: 4.606346607208252\n",
            "Running model iteration 768\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599895000457764\n",
            "Loss: 4.5840983390808105\n",
            "Running model iteration 769\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.607481002807617\n",
            "Loss: 4.58713960647583\n",
            "Running model iteration 770\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610699653625488\n",
            "Loss: 4.622881889343262\n",
            "Running model iteration 771\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6011786460876465\n",
            "Loss: 4.625767707824707\n",
            "Running model iteration 772\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.61782693862915\n",
            "Loss: 4.598257541656494\n",
            "Running model iteration 773\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.582798957824707\n",
            "Loss: 4.6128058433532715\n",
            "Running model iteration 774\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609687805175781\n",
            "Loss: 4.6012163162231445\n",
            "Running model iteration 775\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616708755493164\n",
            "Loss: 4.595355987548828\n",
            "Running model iteration 776\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.623805046081543\n",
            "Loss: 4.602123260498047\n",
            "Running model iteration 777\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6058669090271\n",
            "Loss: 4.609707832336426\n",
            "Running model iteration 778\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625250339508057\n",
            "Loss: 4.62085485458374\n",
            "Running model iteration 779\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.60354471206665\n",
            "Loss: 4.6341423988342285\n",
            "Running model iteration 780\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.622589588165283\n",
            "Loss: 4.629754543304443\n",
            "Running model iteration 781\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.621628761291504\n",
            "Loss: 4.5925068855285645\n",
            "Running model iteration 782\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.613539218902588\n",
            "Loss: 4.61367654800415\n",
            "Running model iteration 783\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.62198543548584\n",
            "Loss: 4.623556613922119\n",
            "Running model iteration 784\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.600051403045654\n",
            "Loss: 4.581026554107666\n",
            "Running model iteration 785\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.595616817474365\n",
            "Loss: 4.633523941040039\n",
            "Running model iteration 786\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599039077758789\n",
            "Loss: 4.590574741363525\n",
            "Running model iteration 787\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.598589897155762\n",
            "Loss: 4.624967575073242\n",
            "Running model iteration 788\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.599852085113525\n",
            "Loss: 4.598158359527588\n",
            "Running model iteration 789\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.625596046447754\n",
            "Loss: 4.611931800842285\n",
            "Running model iteration 790\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.610520839691162\n",
            "Loss: 4.612379550933838\n",
            "Running model iteration 791\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5915021896362305\n",
            "Loss: 4.608704566955566\n",
            "Running model iteration 792\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.627861499786377\n",
            "Loss: 4.584091663360596\n",
            "Running model iteration 793\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.574925422668457\n",
            "Loss: 4.614242076873779\n",
            "Running model iteration 794\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.606773376464844\n",
            "Loss: 4.598462104797363\n",
            "Running model iteration 795\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.609569549560547\n",
            "Loss: 4.5992536544799805\n",
            "Running model iteration 796\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.608348846435547\n",
            "Loss: 4.590671539306641\n",
            "Running model iteration 797\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.624269962310791\n",
            "Loss: 4.601204872131348\n",
            "Running model iteration 798\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.616487503051758\n",
            "Loss: 4.583146572113037\n",
            "Running model iteration 799\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.597601890563965\n",
            "Loss: 4.595882415771484\n",
            "Running model iteration 800\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.6256890296936035\n",
            "Loss: 4.607265472412109\n",
            "Running model iteration 801\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.576404094696045\n",
            "Loss: 4.610240936279297\n",
            "Running model iteration 802\n",
            "torch.Size([50, 64])\n",
            "Loss: 4.5961785316467285\n",
            "Loss: 4.597533226013184\n",
            "Running model iteration 803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(f'Average CrossEntropyLoss: ',sum(final_loss_result)/n_iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7cIAxenbDWO",
        "outputId": "65da4bdc-c020-4496-d54b-c22771804e9e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average CrossEntropyLoss:  4.606250356197357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the histogram\n",
        "plt.hist(final_loss_result, bins=5, edgecolor='black')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.title('Distribution of final_loss_result')\n",
        "plt.xlabel('final_loss_result')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "BB3IQXrWdoIT",
        "outputId": "c337f53e-b5d6-4170-8ead-6e1d825a5ceb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGJVtvv_W7eX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}